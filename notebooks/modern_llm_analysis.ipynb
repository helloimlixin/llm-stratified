{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modern LLM Fiber Bundle Analysis\n",
        "\n",
        "This notebook demonstrates the enhanced fiber bundle hypothesis test framework with state-of-the-art language models and large-scale datasets.\n",
        "\n",
        "## Features Demonstrated\n",
        "\n",
        "1. **Modern LLM Support**: BERT, RoBERTa, DeBERTa, GPT-2, Llama, Sentence Transformers\n",
        "2. **Large-Scale Datasets**: Wikipedia, HuggingFace datasets, Common Crawl\n",
        "3. **Scalable Processing**: Memory management, checkpointing, distributed computing\n",
        "4. **Advanced Analysis**: Multi-model comparison, token-level analysis\n",
        "5. **Rich Visualizations**: Interactive plots and comprehensive analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ðŸš€ Modern LLM Fiber Bundle Analysis Notebook\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¦™ LLaMA-3.2-1B Integration\n",
        "\n",
        "We've successfully integrated Meta's efficient **LLaMA-3.2-1B** model for advanced fiber bundle analysis. This model provides:\n",
        "\n",
        "- **1B parameters** - efficient and accessible\n",
        "- **2048-dimensional embeddings** - rich representation\n",
        "- **Multi-domain analysis** - IMDB, Amazon, Rotten Tomatoes, SST2\n",
        "- **57% rejection rate** - strong fiber bundle violations detected\n",
        "- **Advanced visualizations** - 3D plots and interactive analysis\n",
        "\n",
        "Let's explore the capabilities...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test LLaMA-3.2-1B integration\n",
        "from fiber_bundle_test.embeddings.modern_llms import ModernLLMExtractor\n",
        "\n",
        "# Show available LLaMA models\n",
        "models = ModernLLMExtractor.list_popular_models()\n",
        "llama_models = {k: v for k, v in models.items() if 'llama' in k}\n",
        "\n",
        "print(\"ðŸ¦™ Available LLaMA Models:\")\n",
        "print(\"-\" * 40)\n",
        "for alias, full_name in llama_models.items():\n",
        "    size = \"1B\" if \"3.2-1B\" in full_name else \"3B\" if \"3.2-3B\" in full_name else \"7B+\" \n",
        "    print(f\"{alias:<12} -> {full_name:<35} ({size})\")\n",
        "\n",
        "print(f\"\\nâœ¨ Key Features:\")\n",
        "print(f\"  â€¢ LLaMA-3.2-1B: Most efficient option (1B parameters)\")\n",
        "print(f\"  â€¢ Lower memory requirements than larger models\")\n",
        "print(f\"  â€¢ State-of-the-art architecture improvements\")\n",
        "print(f\"  â€¢ Perfect for research and experimentation\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
