# -*- coding: utf-8 -*-
"""Experiments on Stratified Manifolds in Large Language Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t9nUO_6FcAkNG2olVj0EvrlDOwTO9UH4
"""

!nvidia-smi

"""##  Required Installs"""

# !pip3 install torch torchvision torchaudio

!pip install openai datasets transformers scikit-learn plotly umap-learn

!pip install accelerate sentencepiece bitsandbytes hf_xet

!pip install --upgrade datasets huggingface_hub fsspec

!pip install -U kaleido

import os
import openai
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets, Value
from transformers import BertTokenizer, BertModel  # We only use BERT if we wanted to compare, but here it's not essential
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (needed for 3D projection)
import plotly.express as px
import pandas as pd
from sklearn.decomposition import PCA

from google.colab import userdata
import umap

openai.api_key = userdata.get('openai')

"""## RoBERTa"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets
from datasets import Value
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
import plotly.subplots as sp
from transformers import RobertaTokenizer, RobertaModel
from tqdm.auto import tqdm
import umap

# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"

#############################################################################
# 1. RoBERTa Embedding Functions (Batched)
#############################################################################
roberta_tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
roberta_model = RobertaModel.from_pretrained("roberta-base").to(device)
roberta_model.eval()

def roberta_embed_texts(texts, batch_size=100, max_length=512):
    """
    Generates sentence embeddings using RoBERTa.
    For each batch, tokenizes the texts and computes the mean of the last hidden states.
    """
    embeddings = []
    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        inputs = roberta_tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=max_length)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = roberta_model(**inputs)
        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

def roberta_embed_text(text):
    inputs = roberta_tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = roberta_model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).cpu().numpy().squeeze(0)

def embed_sample(sample):
    return roberta_embed_text(sample["text"])

#############################################################################
# 2. Data Loading & Processing (Diverse Text Datasets)
#############################################################################
def unify_dataset(ds, domain_name, samples_per_domain=100, text_field="text"):
    if text_field != "text":
        ds = ds.map(lambda x: {"text": x[text_field], "label": x["label"]})
    keep_cols = ["text", "label"]
    remove_cols = [c for c in ds.column_names if c not in keep_cols]
    ds = ds.remove_columns(remove_cols)
    ds = ds.map(lambda x: {"label": int(x["label"])})
    ds = ds.cast_column("label", Value("int64"))
    ds_small = ds.select(range(min(samples_per_domain, len(ds))))
    ds_small = ds_small.add_column("domain", [domain_name] * len(ds_small))
    return ds_small

def load_multidomain_sentiment(samples_per_domain=100):
    imdb_ds = unify_dataset(load_dataset("imdb", split=f"train[:{samples_per_domain}]"), "imdb", samples_per_domain)
    rt_ds = unify_dataset(load_dataset("rotten_tomatoes", split=f"train[:{samples_per_domain}]"), "rotten", samples_per_domain)

    ap_raw = load_dataset("amazon_polarity", split=f"train[:{int(2 * samples_per_domain)}]")
    ap_raw = ap_raw.map(lambda x: {"text": f"{x['title']} {x['content']}".strip()})
    ap_ds = unify_dataset(ap_raw, "amazon", samples_per_domain)

    sst2_ds = load_dataset("glue", "sst2", split=f"train[:{samples_per_domain}]")
    sst2_ds = unify_dataset(sst2_ds, "sst2", samples_per_domain, text_field="sentence")

    tweet_ds = load_dataset("tweet_eval", "sentiment", split=f"train[:{samples_per_domain}]")
    tweet_ds = unify_dataset(tweet_ds, "tweet", samples_per_domain, text_field="text")

    ag_news_ds = load_dataset("ag_news", split=f"train[:{samples_per_domain}]")
    ag_news_ds = unify_dataset(ag_news_ds, "ag_news", samples_per_domain, text_field="text")

    return concatenate_datasets([imdb_ds, rt_ds, ap_ds, sst2_ds, tweet_ds, ag_news_ds])

#############################################################################
# 3. Top-K with Straight-Through Estimator (Same)
#############################################################################
class TopKSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, k):
        values, indices = torch.topk(torch.abs(x), k, dim=1)
        mask = torch.zeros_like(x)
        mask.scatter_(1, indices, 1.0)
        return x * mask
    @staticmethod
    def backward(ctx, grad_output):
        return grad_output, None

def topk_st(x, k):
    return TopKSTE.apply(x, k)

#############################################################################
# 4. LISTA-based Dictionary Experts with Varying Sparsity Levels (Same)
#############################################################################
class LISTALayer(nn.Module):
    def __init__(self, input_dim, code_dim, sparsity_level):
        super().__init__()
        self.W = nn.Linear(input_dim, code_dim, bias=False)
        self.S = nn.Linear(code_dim, code_dim, bias=False)
        self.sparsity_level = sparsity_level
    def forward(self, x, z_prev):
        update = self.W(x) + self.S(z_prev)
        new_z = topk_st(update, self.sparsity_level)
        return new_z

class DictionaryExpertLISTA(nn.Module):
    def __init__(self, input_dim, code_dim, num_layers=5, sparsity_level=5):
        super().__init__()
        self.sparsity_level = sparsity_level
        self.dictionary = nn.Parameter(torch.randn(input_dim, code_dim) * 0.01)
        self.num_layers = num_layers
        self.lista_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = LISTALayer(input_dim, code_dim, sparsity_level)
            self.lista_layers.append(layer)
    def forward(self, x):
        batch_size = x.size(0)
        device = x.device
        z = torch.zeros(batch_size, self.dictionary.shape[1], device=device)
        for layer in self.lista_layers:
            z = layer(x, z)
        recon = torch.matmul(z, self.dictionary.T)
        return recon, z

#############################################################################
# 5. Gating Network & Mixture-of-Experts with Hard Expert Assignment (Same)
#############################################################################
class GatingNetworkAttention(nn.Module):
    def __init__(self, input_dim, query_dim, K):
        super().__init__()
        self.query_proj = nn.Linear(input_dim, query_dim)
        self.keys = nn.Parameter(torch.randn(K, query_dim))
    def forward(self, x):
        query = self.query_proj(x)
        logits = torch.matmul(query, self.keys.T) / (query.shape[-1] ** 0.5)
        probs = torch.softmax(logits, dim=1)
        return probs

class MixtureOfDictionaryExperts(nn.Module):
    def __init__(self, input_dim, query_dim, code_dim, K, projection_dim=64, num_lista_layers=5, sparsity_levels=None, threshold=0.9):
        super().__init__()
        self.K = K
        self.threshold = threshold
        self.gating_net = GatingNetworkAttention(input_dim, query_dim, K)
        if sparsity_levels is None:
            sparsity_levels = list(map(int, np.linspace(5, code_dim, K)))
        self.experts = nn.ModuleList([
            DictionaryExpertLISTA(input_dim, code_dim, num_layers=num_lista_layers, sparsity_level=sparsity_levels[i])
            for i in range(K)
        ])
        self.projection_head = nn.Sequential(
            nn.Linear(code_dim, code_dim),
            nn.ReLU(),
            nn.Linear(code_dim, projection_dim)
        )
        self.register_buffer("sparsity_levels", torch.tensor(sparsity_levels, dtype=torch.float32))
    def forward(self, x):
        gating_probs = self.gating_net(x)
        batch_size = gating_probs.size(0)
        zs = []
        for expert in self.experts:
            _, z = expert(x)
            zs.append(z)
        zs = torch.stack(zs, dim=0)
        selected_z = torch.empty(batch_size, zs.size(2), device=x.device)
        for i in range(batch_size):
            p = gating_probs[i]
            p_max = torch.max(p)
            eligible = (p >= self.threshold * p_max).nonzero(as_tuple=True)[0]
            if eligible.numel() == 0:
                idx = torch.argmax(p)
            else:
                eligible_sparsity = self.sparsity_levels[eligible]
                min_idx = torch.argmin(eligible_sparsity)
                idx = eligible[min_idx]
            selected_z[i] = zs[idx, i, :]
        projection = self.projection_head(selected_z)
        return projection

#############################################################################
# 6. Contrastive Loss with Actual Labels (Same)
#############################################################################
def contrastive_loss_with_labels(embeddings, labels, margin=1.0):
    batch_size = embeddings.size(0)
    dist_matrix = torch.cdist(embeddings, embeddings, p=2)
    labels = labels.unsqueeze(1)
    sim_matrix = (labels == labels.T).float()
    pos_loss = sim_matrix * (dist_matrix ** 2)
    neg_loss = (1 - sim_matrix) * torch.clamp(margin - dist_matrix, min=0.0) ** 2
    return (pos_loss + neg_loss).mean()

#############################################################################
# 7. Training Function for MoE with Contrastive Loss (Same)
#############################################################################
def train_contrastive_moe_with_labels(model, data_loader, num_epochs=10, lr=1e-3, margin=1.0, device="cpu"):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0.0
        total_samples = 0
        for batch in data_loader:
            x, batch_labels = batch[0].to(device), batch[1].to(device)
            z = model(x)
            loss = contrastive_loss_with_labels(z, batch_labels, margin)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * x.size(0)
            total_samples += x.size(0)
        avg_loss = total_loss / total_samples
        print(f"Epoch [{epoch+1}/{num_epochs}] - Contrastive Loss: {avg_loss:.9f}")
    return model

#############################################################################
# 8. Execution, Evaluation, and Visualization
#############################################################################
if __name__ == "__main__":
    print("Using device:", device)
    combined_ds = load_multidomain_sentiment(samples_per_domain=500)
    texts = combined_ds["text"]
    domains = combined_ds["domain"]
    labels = torch.tensor(combined_ds["label"], dtype=torch.long)
    print("Generating RoBERTa based embeddings (batched)...")
    all_embeddings = roberta_embed_texts(texts, batch_size=100, max_length=512)
    print("All embeddings shape:", all_embeddings.shape)  # Expected: (num_samples, 768)
    # Use the RoBERTa embeddings as-is.
    pca = PCA(n_components=64)
    emb_64d = pca.fit_transform(all_embeddings)
    print("Reduced shape:", emb_64d.shape)
    X_tensor = torch.tensor(emb_64d, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, labels)
    loader = DataLoader(dataset, batch_size=16, shuffle=True)
    model = MixtureOfDictionaryExperts(
        input_dim=64,
        query_dim=128,
        code_dim=32,
        K=7,
        projection_dim=64,
        num_lista_layers=5,
        sparsity_levels=[8, 12, 16, 20, 24, 28, 32],
        threshold=0.5
    )
    train_contrastive_moe_with_labels(model, loader, num_epochs=10, lr=1e-3, margin=1.0, device=device)
    kmeans = KMeans(n_clusters=5, random_state=42)
    strata = kmeans.fit_predict(emb_64d)
    print("\nIntrinsic Dimensions of Each Stratum (75% Variance Explained):")
    intrinsic_dims = {}
    for s in np.unique(strata):
        indices = np.where(strata == s)[0]
        data_cluster = emb_64d[indices, :]
        if len(data_cluster) < 2:
            intrinsic_dims[s] = 1
        else:
            pca_cluster = PCA()
            pca_cluster.fit(data_cluster)
            cumulative_variance = np.cumsum(pca_cluster.explained_variance_ratio_)
            intrinsic_dims[s] = int(np.searchsorted(cumulative_variance, 0.75) + 1)
        print(f"Stratum {s}: Intrinsic dimension = {intrinsic_dims[s]}")
    silhouette = silhouette_score(emb_64d, strata)
    db_index = davies_bouldin_score(emb_64d, strata)
    ch_index = calinski_harabasz_score(emb_64d, strata)
    print("\nStratum Separation Measures:")
    print(f"Silhouette Score: {silhouette:.4f} (higher is better)")
    print(f"Davies-Bouldin Index: {db_index:.4f} (lower is better)")
    print(f"Calinski-Harabasz Index: {ch_index:.4f} (higher is better)")
    with torch.no_grad():
        gating_probs_all = model.gating_net(X_tensor.to(device)).cpu().numpy()
    df_gating = pd.DataFrame(gating_probs_all, columns=[f"Expert_{i}" for i in range(model.K)])
    df_gating["Stratum"] = strata
    df_gating["Domain"] = domains
    expert_cols = [f"Expert_{i}" for i in range(model.K)]
    avg_gating_per_stratum = df_gating.groupby("Stratum")[expert_cols].mean()
    avg_gating_per_domain = df_gating.groupby("Domain")[expert_cols].mean()
    fig_heatmaps = sp.make_subplots(
        rows=1, cols=2,
        subplot_titles=["Average Gating Probabilities per Stratum", "Average Gating Probabilities per Domain"],
        column_widths=[0.5, 0.5]
    )
    heatmap_stratum = px.imshow(
        avg_gating_per_stratum,
        labels={"x": "Expert", "y": "Stratum", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    heatmap_domain = px.imshow(
        avg_gating_per_domain,
        labels={"x": "Expert", "y": "Domain", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    for trace in heatmap_stratum.data:
        fig_heatmaps.add_trace(trace, row=1, col=1)
    for trace in heatmap_domain.data:
        fig_heatmaps.add_trace(trace, row=1, col=2)
    fig_heatmaps.update_layout(
        title_text="Average Gating Probabilities per Stratum and per Domain",
        width=1200, height=500,
        showlegend=False
    )
    fig_heatmaps.show()
    sparsity_params = np.array([expert.sparsity_level for expert in model.experts])
    weighted_sparsity = np.dot(gating_probs_all, sparsity_params)
    df_weighted = pd.DataFrame({"Weighted_Sparsity": weighted_sparsity, "Stratum": strata})
    avg_sparsity_per_stratum = df_weighted.groupby("Stratum").mean()
    print("\nAverage weighted sparsity level per stratum:")
    print(avg_sparsity_per_stratum)
    expert_assignment = gating_probs_all.argmax(axis=1)
    df_expert_strata = pd.crosstab(expert_assignment, strata, rownames=["Expert Assignment"], colnames=["Stratum"])
    print("\nExpert Assignment vs Stratum (Contingency Table):")
    print(df_expert_strata)
    keys = model.gating_net.keys.detach().cpu().numpy()
    print("\nGating Network Keys (norms):")
    for i, key in enumerate(keys):
         print(f"Expert {i} key norm: {np.linalg.norm(key):.4f}")

    # 3D PCA Visualization (as before)
    pca_3d = PCA(n_components=3)
    emb_3d = pca_3d.fit_transform(emb_64d)
    domain_label = [f"{d}_{l}" for d, l in zip(domains, labels)]
    df_plot = pd.DataFrame({
        "x": emb_3d[:, 0],
        "y": emb_3d[:, 1],
        "z": emb_3d[:, 2],
        "domain": domains,
        "label": labels,
        "Stratum": strata,
        "domain_label": domain_label
    })
    # fig_3d = px.scatter_3d(
    #     df_plot,
    #     x="x", y="y", z="z",
    #     color="domain_label",
    #     hover_data=["domain", "label", "Stratum"],
    #     title="3D Visualization of RoBERTa Embeddings (PCA) with LISTA-based MoE Clusters",
    #     width=1000,
    #     height=700
    # )
    # fig_3d.show()

    # UMAP 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    umap_3d = umap.UMAP(n_components=3, random_state=None).fit_transform(emb_64d)
    df_umap = pd.DataFrame(umap_3d, columns=["component_0", "component_1", "component_2"])
    df_umap["Domain"] = domains
    df_umap["Stratum"] = strata

    # # Create a 3D scatter plot using Plotly
    # fig_umap_3d = px.scatter_3d(
    #     df_umap,
    #     x="component_0", y="component_1", z="component_2",
    #     color="Domain",
    #     symbol="Stratum",
    #     title="UMAP 3D Visualization of Embeddings",
    #     hover_data=["Domain", "Stratum"]
    # )
    # fig_umap_3d.show()

    # # save HTML
    # fig_3d.write_html("roberta_3d_visualization.html")
    # fig_heatmaps.write_html("roberta_heatmap.html")
    # fig_umap_3d.write_html("roberta_umap_3d.html")

    # # save svg
    # fig_3d.write_image("roberta_3d_visualization.svg")
    # fig_heatmaps.write_image("roberta_heatmap.svg")
    # fig_umap_3d.write_image("roberta_umap_3d.svg")

    # … after you’ve computed:
    #   avg_gating_per_stratum  (DataFrame: strata × K experts)
    #   avg_gating_per_domain   (DataFrame: domains × K experts)
    #   emb_3d                  (np.array, N×3 PCA coords)
    #   umap_3d                 (np.array, N×3 UMAP coords)
    #   strata                  (array of length N, int stratum labels)
    #   domains                 (array of length N, string domain labels)
    #   model.K                 (number of experts K)

    # 1) Heatmaps of gating probabilities (2D)
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # Stratum heatmap
    im0 = axes[0].imshow(
        avg_gating_per_stratum.values,
        aspect='auto',
        interpolation='nearest'
    )
    axes[0].set_title("Avg Gating per Stratum")
    axes[0].set_xlabel("Expert")
    axes[0].set_ylabel("Stratum")
    axes[0].set_xticks(range(model.K))
    axes[0].set_xticklabels(avg_gating_per_stratum.columns, rotation=45, ha='right')
    axes[0].set_yticks(range(len(avg_gating_per_stratum.index)))
    axes[0].set_yticklabels(avg_gating_per_stratum.index)
    fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)

    # Domain heatmap
    im1 = axes[1].imshow(
        avg_gating_per_domain.values,
        aspect='auto',
        interpolation='nearest'
    )
    axes[1].set_title("Avg Gating per Domain")
    axes[1].set_xlabel("Expert")
    axes[1].set_ylabel("Domain")
    axes[1].set_xticks(range(model.K))
    axes[1].set_xticklabels(avg_gating_per_domain.columns, rotation=45, ha='right')
    axes[1].set_yticks(range(len(avg_gating_per_domain.index)))
    axes[1].set_yticklabels(avg_gating_per_domain.index)
    fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)

    plt.tight_layout()
    plt.show()


    # 2) PCA → 2D scatter
    pca2 = PCA(n_components=2)
    emb_pca2 = pca2.fit_transform(emb_64d)  # shape: (N,2)

    plt.figure(figsize=(6, 6))
    sc = plt.scatter(
        emb_pca2[:, 0],
        emb_pca2[:, 1],
        c=strata,
        cmap='tab10',
        alpha=0.7,
        s=20
    )
    plt.title("2D PCA of RoBERTa Embeddings")
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.colorbar(sc, label="Stratum")
    plt.tight_layout()
    plt.show()


    # 3) UMAP → 2D scatter
    umap2 = umap.UMAP(n_components=2, random_state=42).fit_transform(emb_64d)

    plt.figure(figsize=(6, 6))
    sc = plt.scatter(
        umap2[:, 0],
        umap2[:, 1],
        c=strata,
        cmap='tab10',
        alpha=0.7,
        s=20
    )
    plt.title("2D UMAP of RoBERTa Embeddings")
    plt.xlabel("UMAP1")
    plt.ylabel("UMAP2")
    plt.colorbar(sc, label="Stratum")
    plt.tight_layout()
    plt.show()

"""## BERT"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets
from datasets import Value
from transformers import AutoModel, AutoTokenizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp
import umap
from sklearn.manifold import TSNE


#############################################################################
# 1. Load a BERT-family Model for Sentence Embeddings
#############################################################################
MODEL_NAME = "bert-base-uncased"  # Change to other BERT variants as needed
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load model and tokenizer
bert_model = AutoModel.from_pretrained(MODEL_NAME).to(device)
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

def bert_embed_text(text):
    """
    Generates sentence embeddings using a BERT-family model.
    Ensures the output is 2D for PCA compatibility.
    """
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512).to(device)
    with torch.no_grad():
        outputs = bert_model(**inputs)
    # Squeeze the extra dimension so that the output shape is [hidden_dim]
    return outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()

#############################################################################
# 2. Data Loading & Processing
#############################################################################
def unify_dataset(ds, domain_name, samples_per_domain=100, text_field="text"):
    """
    Unifies a dataset by:
      1) Keeping only the text field (specified by text_field) and "label" columns.
      2) Converting label to int and casting to Value("int64").
      3) Subsampling up to samples_per_domain.
      4) Adding a "domain" column.
    """
    # Rename text_field to "text" if needed
    if text_field != "text":
        ds = ds.map(lambda x: {"text": x[text_field], "label": x["label"]})
    keep_cols = ["text", "label"]
    remove_cols = [c for c in ds.column_names if c not in keep_cols]
    ds = ds.remove_columns(remove_cols)
    ds = ds.map(lambda x: {"label": int(x["label"])})
    ds = ds.cast_column("label", Value("int64"))
    ds_small = ds.select(range(min(samples_per_domain, len(ds))))
    ds_small = ds_small.add_column("domain", [domain_name] * len(ds_small))
    return ds_small

def load_multidomain_sentiment(samples_per_domain=100):
    """
    Loads and unifies six diverse text datasets:
      - IMDB (long reviews)
      - Rotten Tomatoes (moderate-length reviews)
      - Amazon Polarity (complex reviews)
      - GLUE/SST2 (simpler, shorter sentences)
      - TweetEval (tweets)
      - AG News (news articles)
    Returns a concatenated HuggingFace Dataset.
    """
    imdb_ds = unify_dataset(load_dataset("imdb", split=f"train[:{samples_per_domain}]"), "imdb", samples_per_domain)
    rt_ds = unify_dataset(load_dataset("rotten_tomatoes", split=f"train[:{samples_per_domain}]"), "rotten", samples_per_domain)

    ap_raw = load_dataset("amazon_polarity", split=f"train[:{int(2 * samples_per_domain)}]")
    ap_raw = ap_raw.map(lambda x: {"text": f"{x['title']} {x['content']}".strip()})
    ap_ds = unify_dataset(ap_raw, "amazon", samples_per_domain)

    sst2_ds = load_dataset("glue", "sst2", split=f"train[:{samples_per_domain}]")
    sst2_ds = unify_dataset(sst2_ds, "sst2", samples_per_domain, text_field="sentence")

    tweet_ds = load_dataset("tweet_eval", "sentiment", split=f"train[:{samples_per_domain}]")
    tweet_ds = unify_dataset(tweet_ds, "tweet", samples_per_domain, text_field="text")

    ag_news_ds = load_dataset("ag_news", split=f"train[:{samples_per_domain}]")
    ag_news_ds = unify_dataset(ag_news_ds, "ag_news", samples_per_domain, text_field="text")

    return concatenate_datasets([imdb_ds, rt_ds, ap_ds, sst2_ds, tweet_ds, ag_news_ds])

#############################################################################
# 3. Top-K with Straight-Through Estimator
#############################################################################
class TopKSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, k):
        # x: shape (batch, code_dim); k: int number of nonzeros per sample
        values, indices = torch.topk(torch.abs(x), k, dim=1)
        mask = torch.zeros_like(x)
        mask.scatter_(1, indices, 1.0)
        return x * mask

    @staticmethod
    def backward(ctx, grad_output):
        # Straight-through: pass gradients as if the operator were identity
        return grad_output, None

def topk_st(x, k):
    return TopKSTE.apply(x, k)

#############################################################################
# 4. LISTA-based Dictionary Experts with Varying Sparsity Levels
#############################################################################
class LISTALayer(nn.Module):
    """
    A single unrolled LISTA layer that uses hard top-K selection.
    It computes:
        z_{t+1} = topk( W*x + S*z_t, sparsity_level )
    where topk(...) zeros out all but the top 'sparsity_level' entries.
    """
    def __init__(self, input_dim, code_dim, sparsity_level):
        super().__init__()
        self.W = nn.Linear(input_dim, code_dim, bias=False)  # projects input to code space
        self.S = nn.Linear(code_dim, code_dim, bias=False)     # recurrent connection over code
        self.sparsity_level = sparsity_level

    def forward(self, x, z_prev):
        update = self.W(x) + self.S(z_prev)
        new_z = topk_st(update, self.sparsity_level)
        return new_z

class DictionaryExpertLISTA(nn.Module):
    """
    A dictionary expert that uses an unrolled LISTA network for sparse coding.
    Instead of learning a threshold, each expert picks a fixed number of dictionary atoms,
    determined by the integer 'sparsity_level'.
    """
    def __init__(self, input_dim, code_dim, num_layers=5, sparsity_level=5):
        """
        Args:
            input_dim: Dimension of input (e.g., 64 from PCA).
            code_dim: Dimension of the sparse code.
            num_layers: Number of unrolled LISTA iterations.
            sparsity_level: Integer specifying how many atoms (out of code_dim) to keep.
        """
        super().__init__()
        self.sparsity_level = sparsity_level  # Store the fixed sparsity parameter
        self.dictionary = nn.Parameter(torch.randn(input_dim, code_dim) * 0.01)
        self.num_layers = num_layers
        self.lista_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = LISTALayer(input_dim, code_dim, sparsity_level)
            self.lista_layers.append(layer)

    def forward(self, x):
        batch_size = x.size(0)
        device = x.device
        # Initialize sparse code with zeros
        z = torch.zeros(batch_size, self.dictionary.shape[1], device=device)
        for layer in self.lista_layers:
            z = layer(x, z)
        # Reconstruction: x_hat = z @ dictionary^T
        recon = torch.matmul(z, self.dictionary.T)
        return recon, z

#############################################################################
# 5. Gating Network & Mixture-of-Experts with Hard Expert Assignment
#############################################################################
class GatingNetworkAttention(nn.Module):
    def __init__(self, input_dim, query_dim, K):
        """
        Args:
            input_dim: Dimension of input features.
            query_dim: Dimension for the gating query.
            K: Number of experts.
        """
        super().__init__()
        self.query_proj = nn.Linear(input_dim, query_dim)
        self.keys = nn.Parameter(torch.randn(K, query_dim))

    def forward(self, x):
        query = self.query_proj(x)
        logits = torch.matmul(query, self.keys.T) / (query.shape[-1] ** 0.5)
        probs = torch.softmax(logits, dim=1)
        return probs

class MixtureOfDictionaryExperts(nn.Module):
    def __init__(self, input_dim, query_dim, code_dim, K, projection_dim=64, num_lista_layers=5, sparsity_levels=None, threshold=0.9):
        """
        Args:
            input_dim: Dimensionality of input (e.g., 64 from PCA).
            query_dim: Dimension for the gating network's query projection.
            code_dim: Dimension of the sparse code.
            K: Number of experts.
            projection_dim: Output dimension (set to 64 to match PCA output).
            num_lista_layers: Number of LISTA iterations per expert.
            sparsity_levels: List of integer sparsity levels (length K) for each expert.
                             Each value indicates how many atoms are active.
                             If None, defaults to linearly spaced values between 5 and code_dim.
            threshold: Fraction (e.g., 0.9) of the maximum gating probability used to define
                       eligible experts for hard assignment.
        """
        super().__init__()
        self.K = K
        self.threshold = threshold
        self.gating_net = GatingNetworkAttention(input_dim, query_dim, K)
        if sparsity_levels is None:
            sparsity_levels = list(map(int, np.linspace(5, code_dim, K)))
        self.experts = nn.ModuleList([
            DictionaryExpertLISTA(input_dim, code_dim, num_layers=num_lista_layers, sparsity_level=sparsity_levels[i])
            for i in range(K)
        ])
        self.projection_head = nn.Sequential(
            nn.Linear(code_dim, code_dim),
            nn.ReLU(),
            nn.Linear(code_dim, projection_dim)
        )
        self.register_buffer("sparsity_levels", torch.tensor(sparsity_levels, dtype=torch.float32))

    def forward(self, x):
        # Compute gating probabilities: shape (batch, K)
        gating_probs = self.gating_net(x)
        batch_size = gating_probs.size(0)

        # Compute all experts' sparse codes (shape: (K, batch, code_dim))
        zs = []
        for expert in self.experts:
            _, z = expert(x)
            zs.append(z)
        zs = torch.stack(zs, dim=0)

        # For each sample, select the expert among those with gating probability
        # at least threshold * max(probability) that has the lowest sparsity level.
        selected_z = torch.empty(batch_size, zs.size(2), device=x.device)
        for i in range(batch_size):
            p = gating_probs[i]  # shape: (K,)
            p_max = torch.max(p)
            eligible = (p >= self.threshold * p_max).nonzero(as_tuple=True)[0]
            if eligible.numel() == 0:
                idx = torch.argmax(p)
            else:
                eligible_sparsity = self.sparsity_levels[eligible]
                min_idx = torch.argmin(eligible_sparsity)
                idx = eligible[min_idx]
            selected_z[i] = zs[idx, i, :]

        projection = self.projection_head(selected_z)
        return projection

#############################################################################
# 6. Contrastive Loss with Actual Labels
#############################################################################
def contrastive_loss_with_labels(embeddings, labels, margin=1.0):
    """
    Computes contrastive loss using actual class labels.
    - embeddings: [batch, dim]
    - labels: [batch] (each label is an integer)
    """
    batch_size = embeddings.size(0)
    dist_matrix = torch.cdist(embeddings, embeddings, p=2)
    labels = labels.unsqueeze(1)
    sim_matrix = (labels == labels.T).float()
    pos_loss = sim_matrix * (dist_matrix ** 2)
    neg_loss = (1 - sim_matrix) * torch.clamp(margin - dist_matrix, min=0.0) ** 2
    return (pos_loss + neg_loss).mean()

#############################################################################
# 7. Training Function for MoE with Contrastive Loss
#############################################################################
def train_contrastive_moe_with_labels(model, data_loader, num_epochs=100, lr=1e-3, margin=1.0, device="cpu"):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    model.train()

    for epoch in range(num_epochs):
        total_loss = 0.0
        total_samples = 0

        for batch in data_loader:
            x, batch_labels = batch[0].to(device), batch[1].to(device)
            z = model(x)
            loss = contrastive_loss_with_labels(z, batch_labels, margin)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item() * x.size(0)
            total_samples += x.size(0)
        avg_loss = total_loss / total_samples
        print(f"Epoch [{epoch+1}/{num_epochs}] - Contrastive Loss: {avg_loss:.9f}")
    return model

#############################################################################
# 8. Execution, Evaluation, and Visualization
#############################################################################
if __name__ == "__main__":
    print("Using device:", device)

    # Load multi-domain sentiment dataset (including the new GLUE/SST2 dataset)
    combined_ds = load_multidomain_sentiment(samples_per_domain=50)
    texts = combined_ds["text"]
    domains = combined_ds["domain"]
    labels = torch.tensor(combined_ds["label"], dtype=torch.long)

    print("Generating BERT-based embeddings...")
    all_embeddings = np.array([bert_embed_text(txt) for txt in texts])
    print("All embeddings shape:", all_embeddings.shape)

    # Reduce dimensionality using PCA to 64 dimensions
    pca = PCA(n_components=64)
    emb_64d = pca.fit_transform(all_embeddings)
    print("Reduced shape:", emb_64d.shape)

    # Create a dataset with embeddings and labels
    X_tensor = torch.tensor(emb_64d, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, labels)
    loader = DataLoader(dataset, batch_size=16, shuffle=True)

    # Initialize and train the MoE model using contrastive loss with labels.
    # Here, input_dim = 64, query_dim = 128, code_dim = 32, K = 5 experts,
    # and projection_dim = 64 to match PCA.
    # We assign each expert a different integer sparsity level.
    model = MixtureOfDictionaryExperts(
        input_dim=64,
        query_dim=128,
        code_dim=32,
        K=5,
        projection_dim=64,
        num_lista_layers=5,
        sparsity_levels=[8, 12, 20, 28, 32],
        threshold=0.5  # Adjust threshold for eligibility if needed
    )
    train_contrastive_moe_with_labels(model, loader, num_epochs=10, lr=1e-3, margin=1.0, device=device)

    # Compute cluster assignments on the PCA-reduced embeddings using KMeans
    kmeans = KMeans(n_clusters=5, random_state=None)
    strata = kmeans.fit_predict(emb_64d)

    # Compute intrinsic dimensions per stratum using 75% variance explained.
    # For each stratum, perform PCA and choose the minimum number of components
    # that explain at least 75% of the variance.
    print("\nIntrinsic Dimensions of Each Stratum (75% Variance Explained):")
    intrinsic_dims = {}
    for s in np.unique(strata):
        indices = np.where(strata == s)[0]
        data_cluster = emb_64d[indices, :]
        if len(data_cluster) < 2:
            intrinsic_dims[s] = 1
        else:
            pca_cluster = PCA()
            pca_cluster.fit(data_cluster)
            cumulative_variance = np.cumsum(pca_cluster.explained_variance_ratio_)
            intrinsic_dims[s] = int(np.searchsorted(cumulative_variance, 0.75) + 1)
        print(f"Stratum {s}: Intrinsic dimension = {intrinsic_dims[s]}")

    # Compute cluster separation metrics on PCA embeddings
    silhouette = silhouette_score(emb_64d, strata)
    db_index = davies_bouldin_score(emb_64d, strata)
    ch_index = calinski_harabasz_score(emb_64d, strata)
    print("\nStratum Separation Measures:")
    print(f"Silhouette Score: {silhouette:.4f} (higher is better)")
    print(f"Davies-Bouldin Index: {db_index:.4f} (lower is better)")
    print(f"Calinski-Harabasz Index: {ch_index:.4f} (higher is better)")

    # Extract gating probabilities from the trained MoE model
    with torch.no_grad():
        gating_probs_all = model.gating_net(X_tensor.to(device)).cpu().numpy()

    # Create a DataFrame for gating probabilities with corresponding stratum and domain
    df_gating = pd.DataFrame(gating_probs_all, columns=[f"Expert_{i}" for i in range(model.K)])
    df_gating["Stratum"] = strata
    df_gating["Domain"] = domains

    # Compute average gating probabilities per stratum and per domain (heatmap visualization)
    expert_cols = [f"Expert_{i}" for i in range(model.K)]
    avg_gating_per_stratum = df_gating.groupby("Stratum")[expert_cols].mean()
    avg_gating_per_domain = df_gating.groupby("Domain")[expert_cols].mean()

    fig_heatmaps = sp.make_subplots(
        rows=1, cols=2,
        subplot_titles=["Average Gating Probabilities per Stratum", "Average Gating Probabilities per Domain"],
        column_widths=[0.5, 0.5]
    )
    heatmap_stratum = px.imshow(
        avg_gating_per_stratum,
        labels={"x": "Expert", "y": "Stratum", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    heatmap_domain = px.imshow(
        avg_gating_per_domain,
        labels={"x": "Expert", "y": "Domain", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    for trace in heatmap_stratum.data:
        fig_heatmaps.add_trace(trace, row=1, col=1)
    for trace in heatmap_domain.data:
        fig_heatmaps.add_trace(trace, row=1, col=2)
    fig_heatmaps.update_layout(
        title_text="Average Gating Probabilities per Stratum and per Domain",
        width=1200, height=500,
        showlegend=False
    )
    fig_heatmaps.show()

    # Compute weighted average sparsity level per sample.
    # Each expert has a fixed sparsity parameter (stored in expert.sparsity_level).
    # For each sample, weight these by the gating probabilities.
    sparsity_params = np.array([expert.sparsity_level for expert in model.experts])
    weighted_sparsity = np.dot(gating_probs_all, sparsity_params)
    df_weighted = pd.DataFrame({"Weighted_Sparsity": weighted_sparsity, "Stratum": strata})
    avg_sparsity_per_stratum = df_weighted.groupby("Stratum").mean()
    print("\nAverage weighted sparsity level per stratum:")
    print(avg_sparsity_per_stratum)

    # Compute Expert Assignment per sample (argmax of gating probabilities)
    expert_assignment = gating_probs_all.argmax(axis=1)
    df_expert_strata = pd.crosstab(expert_assignment, strata, rownames=["Expert Assignment"], colnames=["Stratum"])
    print("\nExpert Assignment vs Stratum (Contingency Table):")
    print(df_expert_strata)

    # Visualize gating network key norms
    keys = model.gating_net.keys.detach().cpu().numpy()
    print("\nGating Network Keys (norms):")
    for i, key in enumerate(keys):
         print(f"Expert {i} key norm: {np.linalg.norm(key):.4f}")

    # 3D PCA Scatter Plot of Embeddings, colored by domain with stratum markers
    pca_3d = PCA(n_components=3)
    emb_3d = pca_3d.fit_transform(emb_64d)
    domain_stratum = [f"{d}_{s}" for d, s in zip(domains, strata)]
    df_plot = pd.DataFrame({
        "x": emb_3d[:, 0],
        "y": emb_3d[:, 1],
        "z": emb_3d[:, 2],
        "domain": domains,
        "label": labels,
        "stratum": strata,
        "domain_stratum": domain_stratum
    })
    fig_3d = px.scatter_3d(
        df_plot,
        x="x", y="y", z="z",
        color="domain_stratum",
        hover_data=["domain", "label", "stratum"],
        title="3D Visualization of BERT Embeddings (PCA) with LISTA-based MoE Clusters",
        width=1000,
        height=700
    )
    # make the visualization displayed in tight layout
    fig_3d.update_layout(autosize=True,
                        margin=dict(l=2, r=2, b=2, t=50, pad=1))
    fig_3d.show()

    # UMAP 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    umap_3d = umap.UMAP(n_components=3, random_state=None).fit_transform(emb_64d)
    df_umap = pd.DataFrame({
        "x": umap_3d[:, 0],
        "y": umap_3d[:, 1],
        "z": umap_3d[:, 2],
        "domain": domains,
        "label": labels,
        "stratum": strata,
        "domain_stratum": domain_stratum
     })
    fig_umap_3d = px.scatter_3d(
        df_umap,
        x="x", y="y", z="z",
        color="domain_stratum",
        hover_data=["domain", "label", "stratum"],
        title="UMAP 3D Visualization of Embeddings",
        width=1000,
        height=700
    )

    fig_umap_3d.show()

    # T-SNE 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    tsne_3d = TSNE(n_components=3, random_state=None).fit_transform(emb_64d)
    df_tsne = pd.DataFrame({
        "x": tsne_3d[:, 0],
        "y": tsne_3d[:, 1],
        "z": tsne_3d[:, 2],
        "domain": domains,
        "label": labels,
        "stratum": strata,
        "domain_stratum": domain_stratum
    })

    fig_tsne_3d = px.scatter_3d(
        df_tsne,
        x="x", y="y", z="z",
        color="domain_stratum",
        hover_data=["domain", "label", "stratum"],
        title="T-SNE 3D Visualization of Embeddings",
        width=1000,
        height=700
    )

    fig_tsne_3d.show()

    # save HTML
    fig_3d.write_html("bert_3d_visualization.html")
    fig_heatmaps.write_html("bert_heatmap.html")
    fig_umap_3d.write_html("bert_umap_3d.html")
    fig_tsne_3d.write_html("bert_tsne_3d.html")

"""## GPT3"""

import os
import openai
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets
from datasets import Value
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp

device = "cuda" if torch.cuda.is_available() else "cpu"

#############################################################################
# 1. GPT-3 Embedding Functions (Batched)
#############################################################################
def gpt3_embed_texts(texts, batch_size=100):
    """
    Generates sentence embeddings using GPT-3 (text-embedding-ada-002) in batches.
    """
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        # Filter out empty strings
        batch = [txt for txt in batch if isinstance(txt, str) and len(txt.strip()) > 0]
        if not batch:
            continue
        response = openai.embeddings.create(input=batch, model="text-embedding-ada-002")
        batch_embeddings = [d.embedding for d in response.data]
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

def gpt3_embed_text(text):
    response = openai.Embedding.create(input=[text], model="text-embedding-ada-002")
    embedding = response.data[0].embedding
    return np.array(embedding)

# Unified embedding function for text-only samples.
def embed_sample(sample):
    # Here we assume the sample has a "text" field.
    return gpt3_embed_text(sample["text"])

#############################################################################
# 2. Data Loading & Processing (Diverse Text Datasets)
#############################################################################
def unify_dataset(ds, domain_name, samples_per_domain=100, text_field="text"):
    """
    Unifies a dataset by:
      1) Keeping only the text field (specified by text_field) and "label" columns.
      2) Converting label to int and casting to Value("int64").
      3) Subsampling up to samples_per_domain.
      4) Adding a "domain" column.
    """
    if text_field != "text":
        ds = ds.map(lambda x: {"text": x[text_field], "label": x["label"]})
    keep_cols = ["text", "label"]
    remove_cols = [c for c in ds.column_names if c not in keep_cols]
    ds = ds.remove_columns(remove_cols)
    ds = ds.map(lambda x: {"label": int(x["label"])})
    ds = ds.cast_column("label", Value("int64"))
    ds_small = ds.select(range(min(samples_per_domain, len(ds))))
    ds_small = ds_small.add_column("domain", [domain_name] * len(ds_small))
    return ds_small

def load_multidomain_sentiment(samples_per_domain=100):
    """
    Loads and unifies six diverse text datasets:
      - IMDB (long reviews)
      - Rotten Tomatoes (moderate-length reviews)
      - Amazon Polarity (complex reviews)
      - GLUE/SST2 (simpler, shorter sentences)
      - TweetEval (tweets)
      - AG News (news articles)
    Returns a concatenated HuggingFace Dataset.
    """
    imdb_ds = unify_dataset(load_dataset("imdb", split=f"train[:{samples_per_domain}]"), "imdb", samples_per_domain)
    rt_ds = unify_dataset(load_dataset("rotten_tomatoes", split=f"train[:{samples_per_domain}]"), "rotten", samples_per_domain)

    ap_raw = load_dataset("amazon_polarity", split=f"train[:{int(2 * samples_per_domain)}]")
    ap_raw = ap_raw.map(lambda x: {"text": f"{x['title']} {x['content']}".strip()})
    ap_ds = unify_dataset(ap_raw, "amazon", samples_per_domain)

    sst2_ds = load_dataset("glue", "sst2", split=f"train[:{samples_per_domain}]")
    sst2_ds = unify_dataset(sst2_ds, "sst2", samples_per_domain, text_field="sentence")

    tweet_ds = load_dataset("tweet_eval", "sentiment", split=f"train[:{samples_per_domain}]")
    tweet_ds = unify_dataset(tweet_ds, "tweet", samples_per_domain, text_field="text")

    ag_news_ds = load_dataset("ag_news", split=f"train[:{samples_per_domain}]")
    ag_news_ds = unify_dataset(ag_news_ds, "ag_news", samples_per_domain, text_field="text")

    return concatenate_datasets([imdb_ds, rt_ds, ap_ds, sst2_ds, tweet_ds, ag_news_ds])

#############################################################################
# 3. Top-K with Straight-Through Estimator (Same)
#############################################################################
class TopKSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, k):
        values, indices = torch.topk(torch.abs(x), k, dim=1)
        mask = torch.zeros_like(x)
        mask.scatter_(1, indices, 1.0)
        return x * mask
    @staticmethod
    def backward(ctx, grad_output):
        return grad_output, None

def topk_st(x, k):
    return TopKSTE.apply(x, k)

#############################################################################
# 4. LISTA-based Dictionary Experts with Varying Sparsity Levels (Same)
#############################################################################
class LISTALayer(nn.Module):
    def __init__(self, input_dim, code_dim, sparsity_level):
        super().__init__()
        self.W = nn.Linear(input_dim, code_dim, bias=False)
        self.S = nn.Linear(code_dim, code_dim, bias=False)
        self.sparsity_level = sparsity_level
    def forward(self, x, z_prev):
        update = self.W(x) + self.S(z_prev)
        new_z = topk_st(update, self.sparsity_level)
        return new_z

class DictionaryExpertLISTA(nn.Module):
    def __init__(self, input_dim, code_dim, num_layers=5, sparsity_level=5):
        super().__init__()
        self.sparsity_level = sparsity_level
        self.dictionary = nn.Parameter(torch.randn(input_dim, code_dim) * 0.01)
        self.num_layers = num_layers
        self.lista_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = LISTALayer(input_dim, code_dim, sparsity_level)
            self.lista_layers.append(layer)
    def forward(self, x):
        batch_size = x.size(0)
        device = x.device
        z = torch.zeros(batch_size, self.dictionary.shape[1], device=device)
        for layer in self.lista_layers:
            z = layer(x, z)
        recon = torch.matmul(z, self.dictionary.T)
        return recon, z

#############################################################################
# 5. Gating Network & Mixture-of-Experts with Hard Expert Assignment (Same)
#############################################################################
class GatingNetworkAttention(nn.Module):
    def __init__(self, input_dim, query_dim, K):
        super().__init__()
        self.query_proj = nn.Linear(input_dim, query_dim)
        self.keys = nn.Parameter(torch.randn(K, query_dim))
    def forward(self, x):
        query = self.query_proj(x)
        logits = torch.matmul(query, self.keys.T) / (query.shape[-1] ** 0.5)
        probs = torch.softmax(logits, dim=1)
        return probs

class MixtureOfDictionaryExperts(nn.Module):
    def __init__(self, input_dim, query_dim, code_dim, K, projection_dim=64, num_lista_layers=5, sparsity_levels=None, threshold=0.9):
        super().__init__()
        self.K = K
        self.threshold = threshold
        self.gating_net = GatingNetworkAttention(input_dim, query_dim, K)
        if sparsity_levels is None:
            sparsity_levels = list(map(int, np.linspace(5, code_dim, K)))
        self.experts = nn.ModuleList([
            DictionaryExpertLISTA(input_dim, code_dim, num_layers=num_lista_layers, sparsity_level=sparsity_levels[i])
            for i in range(K)
        ])
        self.projection_head = nn.Sequential(
            nn.Linear(code_dim, code_dim),
            nn.ReLU(),
            nn.Linear(code_dim, projection_dim)
        )
        self.register_buffer("sparsity_levels", torch.tensor(sparsity_levels, dtype=torch.float32))
    def forward(self, x):
        gating_probs = self.gating_net(x)
        batch_size = gating_probs.size(0)
        zs = []
        for expert in self.experts:
            _, z = expert(x)
            zs.append(z)
        zs = torch.stack(zs, dim=0)
        selected_z = torch.empty(batch_size, zs.size(2), device=x.device)
        for i in range(batch_size):
            p = gating_probs[i]
            p_max = torch.max(p)
            eligible = (p >= self.threshold * p_max).nonzero(as_tuple=True)[0]
            if eligible.numel() == 0:
                idx = torch.argmax(p)
            else:
                eligible_sparsity = self.sparsity_levels[eligible]
                min_idx = torch.argmin(eligible_sparsity)
                idx = eligible[min_idx]
            selected_z[i] = zs[idx, i, :]
        projection = self.projection_head(selected_z)
        return projection

#############################################################################
# 6. Contrastive Loss with Actual Labels (Same)
#############################################################################
def contrastive_loss_with_labels(embeddings, labels, margin=1.0):
    batch_size = embeddings.size(0)
    dist_matrix = torch.cdist(embeddings, embeddings, p=2)
    labels = labels.unsqueeze(1)
    sim_matrix = (labels == labels.T).float()
    pos_loss = sim_matrix * (dist_matrix ** 2)
    neg_loss = (1 - sim_matrix) * torch.clamp(margin - dist_matrix, min=0.0) ** 2
    return (pos_loss + neg_loss).mean()

#############################################################################
# 7. Training Function for MoE with Contrastive Loss (Same)
#############################################################################
def train_contrastive_moe_with_labels(model, data_loader, num_epochs=100, lr=1e-3, margin=1.0, device="cpu"):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0.0
        total_samples = 0
        for batch in data_loader:
            x, batch_labels = batch[0].to(device), batch[1].to(device)
            z = model(x)
            loss = contrastive_loss_with_labels(z, batch_labels, margin)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * x.size(0)
            total_samples += x.size(0)
        avg_loss = total_loss / total_samples
        print(f"Epoch [{epoch+1}/{num_epochs}] - Contrastive Loss: {avg_loss:.9f}")
    return model

#############################################################################
# 8. Execution, Evaluation, and Visualization
#############################################################################
if __name__ == "__main__":
    print("Using device:", device)
    # Load six diverse text datasets
    combined_ds = load_multidomain_sentiment(samples_per_domain=500)
    texts = combined_ds["text"]
    domains = combined_ds["domain"]
    labels = torch.tensor(combined_ds["label"], dtype=torch.long)
    print("Generating GPT-3 based embeddings (batched)...")
    all_embeddings = gpt3_embed_texts(texts)
    print("All embeddings shape:", all_embeddings.shape)  # Expected shape: (num_samples, 1536)
    # Since all samples are text-only now, pad embeddings with zeros to reach 2048 dims
    padded_embeddings = np.concatenate([all_embeddings, np.zeros((all_embeddings.shape[0], 512))], axis=1)
    print("Padded embeddings shape:", padded_embeddings.shape)  # (num_samples, 2048)
    # Reduce dimensionality using PCA to 64 dimensions
    pca = PCA(n_components=64)
    emb_64d = pca.fit_transform(padded_embeddings)
    print("Reduced shape:", emb_64d.shape)
    X_tensor = torch.tensor(emb_64d, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, labels)
    loader = DataLoader(dataset, batch_size=16, shuffle=True)
    model = MixtureOfDictionaryExperts(
        input_dim=64,
        query_dim=128,
        code_dim=32,
        K=7,
        projection_dim=64,
        num_lista_layers=5,
        sparsity_levels=[8, 12, 16, 20, 24, 28, 32],
        threshold=0.5
    )
    train_contrastive_moe_with_labels(model, loader, num_epochs=100, lr=1e-3, margin=1.0, device=device)
    kmeans = KMeans(n_clusters=5, random_state=42)
    strata = kmeans.fit_predict(emb_64d)
    print("\nIntrinsic Dimensions of Each Stratum (75% Variance Explained):")
    intrinsic_dims = {}
    for s in np.unique(strata):
        indices = np.where(strata == s)[0]
        data_cluster = emb_64d[indices, :]
        if len(data_cluster) < 2:
            intrinsic_dims[s] = 1
        else:
            pca_cluster = PCA()
            pca_cluster.fit(data_cluster)
            cumulative_variance = np.cumsum(pca_cluster.explained_variance_ratio_)
            intrinsic_dims[s] = int(np.searchsorted(cumulative_variance, 0.75) + 1)
        print(f"Stratum {s}: Intrinsic dimension = {intrinsic_dims[s]}")
    silhouette = silhouette_score(emb_64d, strata)
    db_index = davies_bouldin_score(emb_64d, strata)
    ch_index = calinski_harabasz_score(emb_64d, strata)
    print("\nStratum Separation Measures:")
    print(f"Silhouette Score: {silhouette:.4f} (higher is better)")
    print(f"Davies-Bouldin Index: {db_index:.4f} (lower is better)")
    print(f"Calinski-Harabasz Index: {ch_index:.4f} (higher is better)")
    with torch.no_grad():
        gating_probs_all = model.gating_net(X_tensor.to(device)).cpu().numpy()
    df_gating = pd.DataFrame(gating_probs_all, columns=[f"Expert_{i}" for i in range(model.K)])
    df_gating["Stratum"] = strata
    df_gating["Domain"] = domains
    expert_cols = [f"Expert_{i}" for i in range(model.K)]
    avg_gating_per_stratum = df_gating.groupby("Stratum")[expert_cols].mean()
    avg_gating_per_domain = df_gating.groupby("Domain")[expert_cols].mean()
    fig_heatmaps = sp.make_subplots(
        rows=1, cols=2,
        subplot_titles=["Average Gating Probabilities per Stratum", "Average Gating Probabilities per Domain"],
        column_widths=[0.5, 0.5]
    )
    heatmap_stratum = px.imshow(
        avg_gating_per_stratum,
        labels={"x": "Expert", "y": "Stratum", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    heatmap_domain = px.imshow(
        avg_gating_per_domain,
        labels={"x": "Expert", "y": "Domain", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    for trace in heatmap_stratum.data:
        fig_heatmaps.add_trace(trace, row=1, col=1)
    for trace in heatmap_domain.data:
        fig_heatmaps.add_trace(trace, row=1, col=2)
    fig_heatmaps.update_layout(
        title_text="Average Gating Probabilities per Stratum and per Domain",
        width=1200, height=500,
        showlegend=False
    )
    fig_heatmaps.show()
    sparsity_params = np.array([expert.sparsity_level for expert in model.experts])
    weighted_sparsity = np.dot(gating_probs_all, sparsity_params)
    df_weighted = pd.DataFrame({"Weighted_Sparsity": weighted_sparsity, "Stratum": strata})
    avg_sparsity_per_stratum = df_weighted.groupby("Stratum").mean()
    print("\nAverage weighted sparsity level per stratum:")
    print(avg_sparsity_per_stratum)
    expert_assignment = gating_probs_all.argmax(axis=1)
    df_expert_strata = pd.crosstab(expert_assignment, strata, rownames=["Expert Assignment"], colnames=["Stratum"])
    print("\nExpert Assignment vs Stratum (Contingency Table):")
    print(df_expert_strata)
    keys = model.gating_net.keys.detach().cpu().numpy()
    print("\nGating Network Keys (norms):")
    for i, key in enumerate(keys):
         print(f"Expert {i} key norm: {np.linalg.norm(key):.4f}")
    pca_3d = PCA(n_components=3)
    emb_3d = pca_3d.fit_transform(emb_64d)
    domain_label = [f"{d}_{l}" for d, l in zip(domains, labels)]
    df_plot = pd.DataFrame({
        "x": emb_3d[:, 0],
        "y": emb_3d[:, 1],
        "z": emb_3d[:, 2],
        "domain": domains,
        "label": labels,
        "Stratum": strata,
        "domain_label": domain_label
    })
    fig_3d = px.scatter_3d(
        df_plot,
        x="x", y="y", z="z",
        color="domain_label",
        hover_data=["domain", "label", "Stratum"],
        title="3D Visualization of GPT-3 Embeddings (PCA) with LISTA-based MoE Clusters",
        width=1000,
        height=700
    )
    fig_3d.show()

    # UMAP 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    umap_3d = umap.UMAP(n_components=3, random_state=None).fit_transform(emb_64d)
    df_umap = pd.DataFrame(umap_3d, columns=["component_0", "component_1", "component_2"])
    df_umap["Domain"] = domains
    df_umap["Stratum"] = strata

    # Create a 3D scatter plot using Plotly
    fig_umap_3d = px.scatter_3d(
        df_umap,
        x="component_0", y="component_1", z="component_2",
        color="Domain",
        symbol="Stratum",
        title="UMAP 3D Visualization of Embeddings",
        hover_data=["Domain", "Stratum"]
    )
    fig_umap_3d.show()

    # save HTML
    fig_3d.write_html("gpt3_3d_visualization.html")
    fig_heatmaps.write_html("gpt3_heatmap.html")
    fig_umap_3d.write_html("gpt3_umap_3d.html")

"""## LLama3"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets
from datasets import Value
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp
from transformers import AutoTokenizer, AutoModelForCausalLM
from tqdm.auto import tqdm
import umap

# Set up device
device = "cuda" if torch.cuda.is_available() else "cpu"

#############################################################################
# 1. Load a LLaMA-3 Model for Sentence Embeddings
#############################################################################
# (Replace the model name with the appropriate LLaMA-3 model if available.)
LLAMA_MODEL_NAME = "meta-llama/Llama-3.2-1B"
llama3_tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL_NAME, trust_remote_code=True)
llama3_model = AutoModelForCausalLM.from_pretrained(LLAMA_MODEL_NAME, device_map="auto", trust_remote_code=True)
llama3_model.eval()

def llama3_embed_texts(texts, batch_size=25):
    """
    Generates sentence embeddings using a LLaMA-3 model in batches.
    It tokenizes a list of texts, applies padding using the eos_token as pad_token,
    and then averages the last hidden states over the token dimension.
    """
    # Set pad_token if not already set
    if llama3_tokenizer.pad_token is None:
        llama3_tokenizer.pad_token = llama3_tokenizer.eos_token

    embeddings = []
    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        inputs = llama3_tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512)
        inputs = {k: v.to(llama3_model.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = llama3_model(**inputs, output_hidden_states=True)
        hidden_states = outputs.hidden_states[-1]  # shape: (batch, seq_len, hidden_dim)
        batch_embeddings = hidden_states.mean(dim=1).cpu().numpy()
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

#############################################################################
# 2. Data Loading & Processing (Text-Only Datasets)
#############################################################################
def unify_dataset(ds, domain_name, samples_per_domain=100, text_field="text"):
    if text_field != "text":
        ds = ds.map(lambda x: {"text": x[text_field], "label": x["label"]})
    keep_cols = ["text", "label"]
    remove_cols = [c for c in ds.column_names if c not in keep_cols]
    ds = ds.remove_columns(remove_cols)
    ds = ds.map(lambda x: {"label": int(x["label"])})
    ds = ds.cast_column("label", Value("int64"))
    ds_small = ds.select(range(min(samples_per_domain, len(ds))))
    ds_small = ds_small.add_column("domain", [domain_name] * len(ds_small))
    return ds_small

def load_multidomain_sentiment(samples_per_domain=100):
    """
    Loads and unifies six diverse text datasets:
      - IMDB (long reviews)
      - Rotten Tomatoes (moderate-length reviews)
      - Amazon Polarity (complex reviews)
      - GLUE/SST2 (simpler, shorter sentences)
      - TweetEval (tweets)
      - AG News (news articles)
    Returns a concatenated HuggingFace Dataset.
    """
    imdb_ds = unify_dataset(load_dataset("imdb", split=f"train[:{samples_per_domain}]"), "imdb", samples_per_domain)
    rt_ds = unify_dataset(load_dataset("rotten_tomatoes", split=f"train[:{samples_per_domain}]"), "rotten", samples_per_domain)

    ap_raw = load_dataset("amazon_polarity", split=f"train[:{int(2 * samples_per_domain)}]")
    ap_raw = ap_raw.map(lambda x: {"text": f"{x['title']} {x['content']}".strip()})
    ap_ds = unify_dataset(ap_raw, "amazon", samples_per_domain)

    sst2_ds = load_dataset("glue", "sst2", split=f"train[:{samples_per_domain}]")
    sst2_ds = unify_dataset(sst2_ds, "sst2", samples_per_domain, text_field="sentence")

    tweet_ds = load_dataset("tweet_eval", "sentiment", split=f"train[:{samples_per_domain}]")
    tweet_ds = unify_dataset(tweet_ds, "tweet", samples_per_domain, text_field="text")

    ag_news_ds = load_dataset("ag_news", split=f"train[:{samples_per_domain}]")
    ag_news_ds = unify_dataset(ag_news_ds, "ag_news", samples_per_domain, text_field="text")

    return concatenate_datasets([imdb_ds, rt_ds, ap_ds, sst2_ds, tweet_ds, ag_news_ds])

#############################################################################
# 3. Top-K with Straight-Through Estimator (Same)
#############################################################################
class TopKSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, k):
        values, indices = torch.topk(torch.abs(x), k, dim=1)
        mask = torch.zeros_like(x)
        mask.scatter_(1, indices, 1.0)
        return x * mask
    @staticmethod
    def backward(ctx, grad_output):
        return grad_output, None

def topk_st(x, k):
    return TopKSTE.apply(x, k)

#############################################################################
# 4. LISTA-based Dictionary Experts with Varying Sparsity Levels (Same)
#############################################################################
class LISTALayer(nn.Module):
    def __init__(self, input_dim, code_dim, sparsity_level):
        super().__init__()
        self.W = nn.Linear(input_dim, code_dim, bias=False)
        self.S = nn.Linear(code_dim, code_dim, bias=False)
        self.sparsity_level = sparsity_level
    def forward(self, x, z_prev):
        update = self.W(x) + self.S(z_prev)
        new_z = topk_st(update, self.sparsity_level)
        return new_z

class DictionaryExpertLISTA(nn.Module):
    def __init__(self, input_dim, code_dim, num_layers=5, sparsity_level=5):
        super().__init__()
        self.sparsity_level = sparsity_level
        self.dictionary = nn.Parameter(torch.randn(input_dim, code_dim) * 0.01)
        self.num_layers = num_layers
        self.lista_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = LISTALayer(input_dim, code_dim, sparsity_level)
            self.lista_layers.append(layer)
    def forward(self, x):
        batch_size = x.size(0)
        device = x.device
        z = torch.zeros(batch_size, self.dictionary.shape[1], device=device)
        for layer in self.lista_layers:
            z = layer(x, z)
        recon = torch.matmul(z, self.dictionary.T)
        return recon, z

#############################################################################
# 5. Gating Network & Mixture-of-Experts with Hard Expert Assignment (Same)
#############################################################################
class GatingNetworkAttention(nn.Module):
    def __init__(self, input_dim, query_dim, K):
        super().__init__()
        self.query_proj = nn.Linear(input_dim, query_dim)
        self.keys = nn.Parameter(torch.randn(K, query_dim))
    def forward(self, x):
        query = self.query_proj(x)
        logits = torch.matmul(query, self.keys.T) / (query.shape[-1] ** 0.5)
        probs = torch.softmax(logits, dim=1)
        return probs

class MixtureOfDictionaryExperts(nn.Module):
    def __init__(self, input_dim, query_dim, code_dim, K, projection_dim=64, num_lista_layers=5, sparsity_levels=None, threshold=0.9):
        super().__init__()
        self.K = K
        self.threshold = threshold
        self.gating_net = GatingNetworkAttention(input_dim, query_dim, K)
        if sparsity_levels is None:
            sparsity_levels = list(map(int, np.linspace(5, code_dim, K)))
        self.experts = nn.ModuleList([
            DictionaryExpertLISTA(input_dim, code_dim, num_layers=num_lista_layers, sparsity_level=sparsity_levels[i])
            for i in range(K)
        ])
        self.projection_head = nn.Sequential(
            nn.Linear(code_dim, code_dim),
            nn.ReLU(),
            nn.Linear(code_dim, projection_dim)
        )
        self.register_buffer("sparsity_levels", torch.tensor(sparsity_levels, dtype=torch.float32))
    def forward(self, x):
        gating_probs = self.gating_net(x)
        batch_size = gating_probs.size(0)
        zs = []
        for expert in self.experts:
            _, z = expert(x)
            zs.append(z)
        zs = torch.stack(zs, dim=0)
        selected_z = torch.empty(batch_size, zs.size(2), device=x.device)
        for i in range(batch_size):
            p = gating_probs[i]
            p_max = torch.max(p)
            eligible = (p >= self.threshold * p_max).nonzero(as_tuple=True)[0]
            if eligible.numel() == 0:
                idx = torch.argmax(p)
            else:
                eligible_sparsity = self.sparsity_levels[eligible]
                min_idx = torch.argmin(eligible_sparsity)
                idx = eligible[min_idx]
            selected_z[i] = zs[idx, i, :]
        projection = self.projection_head(selected_z)
        return projection

#############################################################################
# 6. Contrastive Loss with Actual Labels (Same)
#############################################################################
def contrastive_loss_with_labels(embeddings, labels, margin=1.0):
    batch_size = embeddings.size(0)
    dist_matrix = torch.cdist(embeddings, embeddings, p=2)
    labels = labels.unsqueeze(1)
    sim_matrix = (labels == labels.T).float()
    pos_loss = sim_matrix * (dist_matrix ** 2)
    neg_loss = (1 - sim_matrix) * torch.clamp(margin - dist_matrix, min=0.0) ** 2
    return (pos_loss + neg_loss).mean()

#############################################################################
# 7. Training Function for MoE with Contrastive Loss (Same)
#############################################################################
def train_contrastive_moe_with_labels(model, data_loader, num_epochs=100, lr=1e-3, margin=1.0, device="cpu"):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0.0
        total_samples = 0
        for batch in data_loader:
            x, batch_labels = batch[0].to(device), batch[1].to(device)
            z = model(x)
            loss = contrastive_loss_with_labels(z, batch_labels, margin)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * x.size(0)
            total_samples += x.size(0)
        avg_loss = total_loss / total_samples
        print(f"Epoch [{epoch+1}/{num_epochs}] - Contrastive Loss: {avg_loss:.9f}")
    return model

#############################################################################
# 8. Execution, Evaluation, and Visualization
#############################################################################
if __name__ == "__main__":
    print("Using device:", device)
    # Load six diverse text-only datasets
    combined_ds = load_multidomain_sentiment(samples_per_domain=500)
    texts = combined_ds["text"]
    domains = combined_ds["domain"]
    labels = torch.tensor(combined_ds["label"], dtype=torch.long)
    print("Generating LLama-3 based embeddings (batched)...")
    all_embeddings = llama3_embed_texts(texts, batch_size=5)
    print("All embeddings shape:", all_embeddings.shape)  # Expected: (num_samples, 1536)
    # Pad GPT-3 embeddings with zeros to reach 2048 dimensions
    padded_embeddings = np.concatenate([all_embeddings, np.zeros((all_embeddings.shape[0], 512))], axis=1)
    print("Padded embeddings shape:", padded_embeddings.shape)  # Expected: (num_samples, 2048)
    # Reduce dimensionality using PCA to 64 dimensions
    pca = PCA(n_components=64)
    emb_64d = pca.fit_transform(padded_embeddings)
    print("Reduced shape:", emb_64d.shape)
    X_tensor = torch.tensor(emb_64d, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, labels)
    loader = DataLoader(dataset, batch_size=4, shuffle=True)
    model = MixtureOfDictionaryExperts(
        input_dim=64,
        query_dim=128,
        code_dim=32,
        K=7,
        projection_dim=64,
        num_lista_layers=5,
        sparsity_levels=[8, 12, 16, 20, 24, 28, 32],
        threshold=0.5
    )
    train_contrastive_moe_with_labels(model, loader, num_epochs=100, lr=1e-3, margin=1.0, device=device)
    kmeans = KMeans(n_clusters=5, random_state=42)
    strata = kmeans.fit_predict(emb_64d)
    print("\nIntrinsic Dimensions of Each Stratum (75% Variance Explained):")
    intrinsic_dims = {}
    for s in np.unique(strata):
        indices = np.where(strata == s)[0]
        data_cluster = emb_64d[indices, :]
        if len(data_cluster) < 2:
            intrinsic_dims[s] = 1
        else:
            pca_cluster = PCA()
            pca_cluster.fit(data_cluster)
            cumulative_variance = np.cumsum(pca_cluster.explained_variance_ratio_)
            intrinsic_dims[s] = int(np.searchsorted(cumulative_variance, 0.75) + 1)
        print(f"Stratum {s}: Intrinsic dimension = {intrinsic_dims[s]}")
    silhouette = silhouette_score(emb_64d, strata)
    db_index = davies_bouldin_score(emb_64d, strata)
    ch_index = calinski_harabasz_score(emb_64d, strata)
    print("\nStratum Separation Measures:")
    print(f"Silhouette Score: {silhouette:.4f} (higher is better)")
    print(f"Davies-Bouldin Index: {db_index:.4f} (lower is better)")
    print(f"Calinski-Harabasz Index: {ch_index:.4f} (higher is better)")
    with torch.no_grad():
        gating_probs_all = model.gating_net(X_tensor.to(device)).cpu().numpy()
    df_gating = pd.DataFrame(gating_probs_all, columns=[f"Expert_{i}" for i in range(model.K)])
    df_gating["Stratum"] = strata
    df_gating["Domain"] = domains
    expert_cols = [f"Expert_{i}" for i in range(model.K)]
    avg_gating_per_stratum = df_gating.groupby("Stratum")[expert_cols].mean()
    avg_gating_per_domain = df_gating.groupby("Domain")[expert_cols].mean()
    fig_heatmaps = sp.make_subplots(
        rows=1, cols=2,
        subplot_titles=["Average Gating Probabilities per Stratum", "Average Gating Probabilities per Domain"],
        column_widths=[0.5, 0.5]
    )
    heatmap_stratum = px.imshow(
        avg_gating_per_stratum,
        labels={"x": "Expert", "y": "Stratum", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    heatmap_domain = px.imshow(
        avg_gating_per_domain,
        labels={"x": "Expert", "y": "Domain", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    for trace in heatmap_stratum.data:
        fig_heatmaps.add_trace(trace, row=1, col=1)
    for trace in heatmap_domain.data:
        fig_heatmaps.add_trace(trace, row=1, col=2)
    fig_heatmaps.update_layout(
        title_text="Average Gating Probabilities per Stratum and per Domain",
        width=1200, height=500,
        showlegend=False
    )
    fig_heatmaps.show()
    sparsity_params = np.array([expert.sparsity_level for expert in model.experts])
    weighted_sparsity = np.dot(gating_probs_all, sparsity_params)
    df_weighted = pd.DataFrame({"Weighted_Sparsity": weighted_sparsity, "Stratum": strata})
    avg_sparsity_per_stratum = df_weighted.groupby("Stratum").mean()
    print("\nAverage weighted sparsity level per stratum:")
    print(avg_sparsity_per_stratum)
    expert_assignment = gating_probs_all.argmax(axis=1)
    df_expert_strata = pd.crosstab(expert_assignment, strata, rownames=["Expert Assignment"], colnames=["Stratum"])
    print("\nExpert Assignment vs Stratum (Contingency Table):")
    print(df_expert_strata)
    keys = model.gating_net.keys.detach().cpu().numpy()
    print("\nGating Network Keys (norms):")
    for i, key in enumerate(keys):
         print(f"Expert {i} key norm: {np.linalg.norm(key):.4f}")
    pca_3d = PCA(n_components=3)
    emb_3d = pca_3d.fit_transform(emb_64d)
    domain_label = [f"{d}_{l}" for d, l in zip(domains, labels)]
    df_plot = pd.DataFrame({
        "x": emb_3d[:, 0],
        "y": emb_3d[:, 1],
        "z": emb_3d[:, 2],
        "domain": domains,
        "label": labels,
        "Stratum": strata,
        "domain_label": domain_label
    })
    fig_3d = px.scatter_3d(
        df_plot,
        x="x", y="y", z="z",
        color="domain_label",
        hover_data=["domain", "label", "Stratum"],
        title="3D Visualization of LLama-3 Embeddings (PCA) with LISTA-based MoE Clusters",
        width=1000,
        height=700
    )
    fig_3d.show()

    # UMAP 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    umap_3d = umap.UMAP(n_components=3, random_state=None).fit_transform(emb_64d)
    df_umap = pd.DataFrame(umap_3d, columns=["component_0", "component_1", "component_2"])
    df_umap["Domain"] = domains
    df_umap["Stratum"] = strata

    # Create a 3D scatter plot using Plotly
    fig_umap_3d = px.scatter_3d(
        df_umap,
        x="component_0", y="component_1", z="component_2",
        color="Domain",
        symbol="Stratum",
        title="UMAP 3D Visualization of Embeddings",
        hover_data=["Domain", "Stratum"]
    )
    fig_umap_3d.show()

    # save HTML
    fig_3d.write_html("llama_3d_visualization.html")
    fig_heatmaps.write_html("llama_heatmap.html")
    fig_umap_3d.write_html("llama_umap_3d.html")

"""## DeepSeek"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datasets import load_dataset, concatenate_datasets
from datasets import Value
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp
from transformers import AutoTokenizer, AutoModelForCausalLM
from tqdm.auto import tqdm
import umap

# Choose a DeepSeek model identifier (update if needed)
DEEPSEEK_MODEL_NAME = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"  # Verify this model exists and is accessible

device = "cuda" if torch.cuda.is_available() else "cpu"

# Load DeepSeek tokenizer and model
deepseek_tokenizer = AutoTokenizer.from_pretrained(DEEPSEEK_MODEL_NAME)
deepseek_model = AutoModelForCausalLM.from_pretrained(DEEPSEEK_MODEL_NAME).to(device)
deepseek_model.eval()

#############################################################################
# 1. DeepSeek Embedding Function (Batched)
#############################################################################
def deepseek_embed_texts(texts, batch_size=100):
    """
    Generates sentence embeddings using the DeepSeek model in batches.
    Uses average pooling over the token dimension of the last hidden state.
    """
    embeddings = []
    for i in tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        inputs = deepseek_tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = deepseek_model(**inputs, output_hidden_states=True)
        # Average pooling over token dimension
        hidden_states = outputs.hidden_states[-1]  # shape: (batch, seq_len, hidden_dim)
        batch_embeddings = hidden_states.mean(dim=1).cpu().numpy()
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

#############################################################################
# 2. Data Loading & Processing (Diverse Text Datasets)
#############################################################################
def unify_dataset(ds, domain_name, samples_per_domain=100, text_field="text"):
    if text_field != "text":
        ds = ds.map(lambda x: {"text": x[text_field], "label": x["label"]})
    keep_cols = ["text", "label"]
    remove_cols = [c for c in ds.column_names if c not in keep_cols]
    ds = ds.remove_columns(remove_cols)
    ds = ds.map(lambda x: {"label": int(x["label"])})
    ds = ds.cast_column("label", Value("int64"))
    ds_small = ds.select(range(min(samples_per_domain, len(ds))))
    ds_small = ds_small.add_column("domain", [domain_name] * len(ds_small))
    return ds_small

def load_multidomain_sentiment(samples_per_domain=100):
    imdb_ds = unify_dataset(load_dataset("imdb", split=f"train[:{samples_per_domain}]"), "imdb", samples_per_domain)
    rt_ds = unify_dataset(load_dataset("rotten_tomatoes", split=f"train[:{samples_per_domain}]"), "rotten", samples_per_domain)

    ap_raw = load_dataset("amazon_polarity", split=f"train[:{int(2 * samples_per_domain)}]")
    ap_raw = ap_raw.map(lambda x: {"text": f"{x['title']} {x['content']}".strip()})
    ap_ds = unify_dataset(ap_raw, "amazon", samples_per_domain)

    sst2_ds = load_dataset("glue", "sst2", split=f"train[:{samples_per_domain}]")
    sst2_ds = unify_dataset(sst2_ds, "sst2", samples_per_domain, text_field="sentence")

    tweet_ds = load_dataset("tweet_eval", "sentiment", split=f"train[:{samples_per_domain}]")
    tweet_ds = unify_dataset(tweet_ds, "tweet", samples_per_domain, text_field="text")

    ag_news_ds = load_dataset("ag_news", split=f"train[:{samples_per_domain}]")
    ag_news_ds = unify_dataset(ag_news_ds, "ag_news", samples_per_domain, text_field="text")

    return concatenate_datasets([imdb_ds, rt_ds, ap_ds, sst2_ds, tweet_ds, ag_news_ds])

#############################################################################
# 3. Top-K with Straight-Through Estimator (Same)
#############################################################################
class TopKSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, k):
        values, indices = torch.topk(torch.abs(x), k, dim=1)
        mask = torch.zeros_like(x)
        mask.scatter_(1, indices, 1.0)
        return x * mask
    @staticmethod
    def backward(ctx, grad_output):
        return grad_output, None

def topk_st(x, k):
    return TopKSTE.apply(x, k)

#############################################################################
# 4. LISTA-based Dictionary Experts with Varying Sparsity Levels (Same)
#############################################################################
class LISTALayer(nn.Module):
    def __init__(self, input_dim, code_dim, sparsity_level):
        super().__init__()
        self.W = nn.Linear(input_dim, code_dim, bias=False)
        self.S = nn.Linear(code_dim, code_dim, bias=False)
        self.sparsity_level = sparsity_level
    def forward(self, x, z_prev):
        update = self.W(x) + self.S(z_prev)
        new_z = topk_st(update, self.sparsity_level)
        return new_z

class DictionaryExpertLISTA(nn.Module):
    def __init__(self, input_dim, code_dim, num_layers=5, sparsity_level=5):
        super().__init__()
        self.sparsity_level = sparsity_level
        self.dictionary = nn.Parameter(torch.randn(input_dim, code_dim) * 0.01)
        self.num_layers = num_layers
        self.lista_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = LISTALayer(input_dim, code_dim, sparsity_level)
            self.lista_layers.append(layer)
    def forward(self, x):
        batch_size = x.size(0)
        device = x.device
        z = torch.zeros(batch_size, self.dictionary.shape[1], device=device)
        for layer in self.lista_layers:
            z = layer(x, z)
        recon = torch.matmul(z, self.dictionary.T)
        return recon, z

#############################################################################
# 5. Gating Network & Mixture-of-Experts with Hard Expert Assignment (Same)
#############################################################################
class GatingNetworkAttention(nn.Module):
    def __init__(self, input_dim, query_dim, K):
        super().__init__()
        self.query_proj = nn.Linear(input_dim, query_dim)
        self.keys = nn.Parameter(torch.randn(K, query_dim))
    def forward(self, x):
        query = self.query_proj(x)
        logits = torch.matmul(query, self.keys.T) / (query.shape[-1] ** 0.5)
        probs = torch.softmax(logits, dim=1)
        return probs

class MixtureOfDictionaryExperts(nn.Module):
    def __init__(self, input_dim, query_dim, code_dim, K, projection_dim=64, num_lista_layers=5, sparsity_levels=None, threshold=0.9):
        super().__init__()
        self.K = K
        self.threshold = threshold
        self.gating_net = GatingNetworkAttention(input_dim, query_dim, K)
        if sparsity_levels is None:
            sparsity_levels = list(map(int, np.linspace(5, code_dim, K)))
        self.experts = nn.ModuleList([
            DictionaryExpertLISTA(input_dim, code_dim, num_layers=num_lista_layers, sparsity_level=sparsity_levels[i])
            for i in range(K)
        ])
        self.projection_head = nn.Sequential(
            nn.Linear(code_dim, code_dim),
            nn.ReLU(),
            nn.Linear(code_dim, projection_dim)
        )
        self.register_buffer("sparsity_levels", torch.tensor(sparsity_levels, dtype=torch.float32))
    def forward(self, x):
        gating_probs = self.gating_net(x)
        batch_size = gating_probs.size(0)
        zs = []
        for expert in self.experts:
            _, z = expert(x)
            zs.append(z)
        zs = torch.stack(zs, dim=0)
        selected_z = torch.empty(batch_size, zs.size(2), device=x.device)
        for i in range(batch_size):
            p = gating_probs[i]
            p_max = torch.max(p)
            eligible = (p >= self.threshold * p_max).nonzero(as_tuple=True)[0]
            if eligible.numel() == 0:
                idx = torch.argmax(p)
            else:
                eligible_sparsity = self.sparsity_levels[eligible]
                min_idx = torch.argmin(eligible_sparsity)
                idx = eligible[min_idx]
            selected_z[i] = zs[idx, i, :]
        projection = self.projection_head(selected_z)
        return projection

#############################################################################
# 6. Contrastive Loss with Actual Labels (Same)
#############################################################################
def contrastive_loss_with_labels(embeddings, labels, margin=1.0):
    batch_size = embeddings.size(0)
    dist_matrix = torch.cdist(embeddings, embeddings, p=2)
    labels = labels.unsqueeze(1)
    sim_matrix = (labels == labels.T).float()
    pos_loss = sim_matrix * (dist_matrix ** 2)
    neg_loss = (1 - sim_matrix) * torch.clamp(margin - dist_matrix, min=0.0) ** 2
    return (pos_loss + neg_loss).mean()

#############################################################################
# 7. Training Function for MoE with Contrastive Loss (Same)
#############################################################################
def train_contrastive_moe_with_labels(model, data_loader, num_epochs=100, lr=1e-3, margin=1.0, device="cpu"):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0.0
        total_samples = 0
        for batch in data_loader:
            x, batch_labels = batch[0].to(device), batch[1].to(device)
            z = model(x)
            loss = contrastive_loss_with_labels(z, batch_labels, margin)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * x.size(0)
            total_samples += x.size(0)
        avg_loss = total_loss / total_samples
        print(f"Epoch [{epoch+1}/{num_epochs}] - Contrastive Loss: {avg_loss:.9f}")
    return model

#############################################################################
# 8. Execution, Evaluation, and Visualization
#############################################################################
if __name__ == "__main__":
    print("Using device:", device)
    combined_ds = load_multidomain_sentiment(samples_per_domain=500)
    texts = combined_ds["text"]
    domains = combined_ds["domain"]
    labels = torch.tensor(combined_ds["label"], dtype=torch.long)
    print("Generating DeepSeek-R1-Distill-Qwen-1.5B based embeddings (batched)...")
    all_embeddings = deepseek_embed_texts(texts, batch_size=5)
    print("All embeddings shape:", all_embeddings.shape)  # Expected: (num_samples, 1536)
    padded_embeddings = np.concatenate([all_embeddings, np.zeros((all_embeddings.shape[0], 512))], axis=1)
    print("Padded embeddings shape:", padded_embeddings.shape)  # Expected: (num_samples, 2048)
    pca = PCA(n_components=64)
    emb_64d = pca.fit_transform(padded_embeddings)
    print("Reduced shape:", emb_64d.shape)
    X_tensor = torch.tensor(emb_64d, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, labels)
    loader = DataLoader(dataset, batch_size=16, shuffle=True)
    model = MixtureOfDictionaryExperts(
        input_dim=64,
        query_dim=128,
        code_dim=32,
        K=7,
        projection_dim=64,
        num_lista_layers=5,
        sparsity_levels=[8, 12, 16, 20, 24, 28, 32],
        threshold=0.5
    )
    train_contrastive_moe_with_labels(model, loader, num_epochs=100, lr=1e-3, margin=1.0, device=device)
    kmeans = KMeans(n_clusters=5, random_state=42)
    strata = kmeans.fit_predict(emb_64d)
    print("\nIntrinsic Dimensions of Each Stratum (75% Variance Explained):")
    intrinsic_dims = {}
    for s in np.unique(strata):
        indices = np.where(strata == s)[0]
        data_cluster = emb_64d[indices, :]
        if len(data_cluster) < 2:
            intrinsic_dims[s] = 1
        else:
            pca_cluster = PCA()
            pca_cluster.fit(data_cluster)
            cumulative_variance = np.cumsum(pca_cluster.explained_variance_ratio_)
            intrinsic_dims[s] = int(np.searchsorted(cumulative_variance, 0.75) + 1)
        print(f"Stratum {s}: Intrinsic dimension = {intrinsic_dims[s]}")
    silhouette = silhouette_score(emb_64d, strata)
    db_index = davies_bouldin_score(emb_64d, strata)
    ch_index = calinski_harabasz_score(emb_64d, strata)
    print("\nStratum Separation Measures:")
    print(f"Silhouette Score: {silhouette:.4f} (higher is better)")
    print(f"Davies-Bouldin Index: {db_index:.4f} (lower is better)")
    print(f"Calinski-Harabasz Index: {ch_index:.4f} (higher is better)")
    with torch.no_grad():
        gating_probs_all = model.gating_net(X_tensor.to(device)).cpu().numpy()
    df_gating = pd.DataFrame(gating_probs_all, columns=[f"Expert_{i}" for i in range(model.K)])
    df_gating["Stratum"] = strata
    df_gating["Domain"] = domains
    expert_cols = [f"Expert_{i}" for i in range(model.K)]
    avg_gating_per_stratum = df_gating.groupby("Stratum")[expert_cols].mean()
    avg_gating_per_domain = df_gating.groupby("Domain")[expert_cols].mean()
    fig_heatmaps = sp.make_subplots(
        rows=1, cols=2,
        subplot_titles=["Average Gating Probabilities per Stratum", "Average Gating Probabilities per Domain"],
        column_widths=[0.5, 0.5]
    )
    heatmap_stratum = px.imshow(
        avg_gating_per_stratum,
        labels={"x": "Expert", "y": "Stratum", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    heatmap_domain = px.imshow(
        avg_gating_per_domain,
        labels={"x": "Expert", "y": "Domain", "color": "Avg Gating Probability"},
        color_continuous_scale="plasma"
    )
    for trace in heatmap_stratum.data:
        fig_heatmaps.add_trace(trace, row=1, col=1)
    for trace in heatmap_domain.data:
        fig_heatmaps.add_trace(trace, row=1, col=2)
    fig_heatmaps.update_layout(
        title_text="Average Gating Probabilities per Stratum and per Domain",
        width=1200, height=500,
        showlegend=False
    )
    fig_heatmaps.show()
    sparsity_params = np.array([expert.sparsity_level for expert in model.experts])
    weighted_sparsity = np.dot(gating_probs_all, sparsity_params)
    df_weighted = pd.DataFrame({"Weighted_Sparsity": weighted_sparsity, "Stratum": strata})
    avg_sparsity_per_stratum = df_weighted.groupby("Stratum").mean()
    print("\nAverage weighted sparsity level per stratum:")
    print(avg_sparsity_per_stratum)
    expert_assignment = gating_probs_all.argmax(axis=1)
    df_expert_strata = pd.crosstab(expert_assignment, strata, rownames=["Expert Assignment"], colnames=["Stratum"])
    print("\nExpert Assignment vs Stratum (Contingency Table):")
    print(df_expert_strata)
    keys = model.gating_net.keys.detach().cpu().numpy()
    print("\nGating Network Keys (norms):")
    for i, key in enumerate(keys):
         print(f"Expert {i} key norm: {np.linalg.norm(key):.4f}")
    pca_3d = PCA(n_components=3)
    emb_3d = pca_3d.fit_transform(emb_64d)
    domain_label = [f"{d}_{l}" for d, l in zip(domains, labels)]
    df_plot = pd.DataFrame({
        "x": emb_3d[:, 0],
        "y": emb_3d[:, 1],
        "z": emb_3d[:, 2],
        "domain": domains,
        "label": labels,
        "Stratum": strata,
        "domain_label": domain_label
    })
    fig_3d = px.scatter_3d(
        df_plot,
        x="x", y="y", z="z",
        color="domain_label",
        hover_data=["domain", "label", "Stratum"],
        title="3D Visualization of DeepSeek-R1-Distill-Qwen-1.5B Embeddings (PCA) with LISTA-based MoE Clusters",
        width=1000,
        height=700
    )
    fig_3d.show()

    # UMAP 3D projection: reduce emb_64d (from PCA) to 3 dimensions
    umap_3d = umap.UMAP(n_components=3, random_state=None).fit_transform(emb_64d)
    df_umap = pd.DataFrame(umap_3d, columns=["component_0", "component_1", "component_2"])
    df_umap["Domain"] = domains
    df_umap["Stratum"] = strata

    # Create a 3D scatter plot using Plotly
    fig_umap_3d = px.scatter_3d(
        df_umap,
        x="component_0", y="component_1", z="component_2",
        color="Domain",
        symbol="Stratum",
        title="UMAP 3D Visualization of Embeddings",
        hover_data=["Domain", "Stratum"]
    )
    fig_umap_3d.show()

    # save HTML
    fig_3d.write_html("deepseek_3d_visualization.html")
    fig_heatmaps.write_html("deepseek_heatmap.html")
    fig_umap_3d.write_html("deepseek_umap_3d.html")

!pip install Cython
!pip install Ripser
!pip install persim
!pip install gudhi

import numpy as np
from scipy.sparse.linalg import eigsh
from sklearn.neighbors import NearestNeighbors
from ripser import ripser
from persim import plot_diagrams
import gudhi as gd
from scipy.stats import entropy
from scipy.spatial.distance import pdist, squareform
import torch
import torch.nn as nn
import torch.nn.functional as F

class LocalDimensionEstimator:
    """Estimates local intrinsic dimension using multiple methods."""

    def __init__(self, n_neighbors=15, max_dim=100):
        self.n_neighbors = n_neighbors
        self.max_dim = max_dim

    def _mle_dimension(self, X, local_region):
        """
        Maximum Likelihood Estimation of local intrinsic dimension.
        Uses local_region for neighborhood statistics.
        """
        if len(local_region) < 2:
            return 1.0, 0.0

        k = min(self.n_neighbors, len(local_region) - 1)

        # Get k nearest neighbors using local_region
        nbrs = NearestNeighbors(n_neighbors=k+1).fit(local_region)
        distances, _ = nbrs.kneighbors(X)
        distances = distances[:, 1:]  # Exclude self-distance

        # Compute MLE estimate
        log_dists = np.log(distances / distances[:, -1:][:, np.newaxis])
        inv_mle = np.mean(log_dists, axis=1)
        mle_dims = -1 / inv_mle

        return np.mean(mle_dims), np.std(mle_dims)


    def correlation_dimension(self, X, eps_range=None):
        """
        Estimates correlation dimension using point-wise correlation sum.
        """
        if eps_range is None:
            dists = pdist(X)
            eps_range = np.logspace(np.log10(np.min(dists)), np.log10(np.max(dists)), 20)

        dists = squareform(pdist(X))
        N = len(X)

        correlation_sums = []
        for eps in eps_range:
            correlation_sum = np.sum(dists < eps) / (N * (N-1))
            correlation_sums.append(correlation_sum)

        # Estimate dimension from slope
        log_eps = np.log(eps_range)
        log_corr = np.log(correlation_sums)
        slope = np.polyfit(log_eps, log_corr, 1)[0]

        return slope

    def tda_dimension(self, X):
        """
        Estimates dimension using persistent homology.
        """
        # Compute persistent homology
        diagrams = ripser(X)['dgms']

        # Analyze persistence lifetimes
        lifetimes = []
        for dim, diagram in enumerate(diagrams):
            if len(diagram) > 0:
                lifetime = diagram[:, 1] - diagram[:, 0]
                lifetimes.append(np.mean(lifetime[np.isfinite(lifetime)]))

        # Estimate dimension from lifetime decay
        if len(lifetimes) > 1:
            decay_rate = -np.polyfit(range(len(lifetimes)), np.log(lifetimes), 1)[0]
            return decay_rate
        return 1

    def estimate_dimension(self, X, local_region=None):
        """
        Combines multiple dimension estimates.

        Args:
            X: Data point(s) to estimate dimension for
            local_region: Optional reference dataset for local neighborhood
        """
        if local_region is None:
            if len(X) < self.n_neighbors + 1:
                # If we don't have enough points, return minimum dimension
                return {
                    'dimension': 1.0,
                    'mle': 1.0,
                    'mle_std': 0.0,
                    'correlation': 1.0,
                    'tda': 1.0
                }
            local_region = X

        # Compute MLE dimension using local region
        mle_dim, mle_std = self._mle_dimension(X, local_region)

        # Compute correlation dimension if we have enough points
        if len(local_region) > self.n_neighbors:
            corr_dim = self._correlation_dimension(local_region)
            tda_dim = self._tda_dimension(local_region)
        else:
            corr_dim = mle_dim
            tda_dim = mle_dim

        # Weighted average based on confidence/stability
        weights = [1.0, 0.8, 0.6]  # Weights for MLE, correlation, and TDA
        dims = np.array([mle_dim, corr_dim, tda_dim])
        weighted_dim = np.average(dims, weights=weights)

        return {
            'dimension': weighted_dim,
            'mle': mle_dim,
            'mle_std': mle_std,
            'correlation': corr_dim,
            'tda': tda_dim
        }

class ManifoldIntersectionDetector:
    """Detects and characterizes intersections between manifolds."""

    def __init__(self, n_neighbors=15, min_pts=5):
        self.n_neighbors = n_neighbors
        self.min_pts = min_pts

    def compute_local_tangent_space(self, X, point_idx):
        """
        Computes local tangent space using PCA on neighborhood.
        """
        # Get local neighborhood
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors).fit(X)
        distances, indices = nbrs.kneighbors(X[point_idx:point_idx+1])
        neighborhood = X[indices[0]]

        # Center the neighborhood
        centered = neighborhood - np.mean(neighborhood, axis=0)

        # Compute SVD
        U, S, Vt = np.linalg.svd(centered, full_matrices=False)

        return Vt, S

    def detect_intersection(self, X, labels, point_idx):
        """
        Detects if a point lies in manifold intersection.
        """
        # Get local neighborhood
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors).fit(X)
        distances, indices = nbrs.kneighbors(X[point_idx:point_idx+1])
        neighborhood_labels = labels[indices[0]]

        # Check for multiple manifolds in neighborhood
        unique_labels = np.unique(neighborhood_labels)
        if len(unique_labels) > 1:
            # Compute tangent spaces for each manifold
            tangent_spaces = []
            for label in unique_labels:
                mask = neighborhood_labels == label
                if np.sum(mask) >= self.min_pts:
                    Vt, S = self.compute_local_tangent_space(X[indices[0][mask]], 0)
                    tangent_spaces.append((Vt, S))

            # Analyze intersection angles
            if len(tangent_spaces) > 1:
                angles = self._compute_intersection_angles(tangent_spaces)
                return True, angles

        return False, None

    def _compute_intersection_angles(self, tangent_spaces):
        """
        Computes principal angles between tangent spaces.
        """
        angles = []
        for i in range(len(tangent_spaces)):
            for j in range(i+1, len(tangent_spaces)):
                V1, _ = tangent_spaces[i]
                V2, _ = tangent_spaces[j]

                # Compute principal angles
                M = V1 @ V2.T
                S = np.linalg.svd(M, compute_uv=False)
                angles.append(np.arccos(np.clip(S, -1, 1)))

        return angles

class GeometricHarmonicAnalysis:
    """
    Implements geometric harmonic analysis for manifold learning.
    """

    def __init__(self, n_eigenvectors=50, n_neighbors=15):
        self.n_eigenvectors = n_eigenvectors
        self.n_neighbors = n_neighbors

    def compute_laplacian_eigenmaps(self, X):
        """
        Computes Laplacian eigenmaps of the data.
        """
        # Construct adjacency matrix
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors).fit(X)
        adj_matrix = nbrs.kneighbors_graph(X, mode='distance')
        adj_matrix = np.array(adj_matrix.todense())

        # Gaussian kernel
        sigma = np.mean(adj_matrix[adj_matrix > 0])
        W = np.exp(-adj_matrix**2 / (2 * sigma**2))

        # Compute normalized Laplacian
        D = np.diag(np.sum(W, axis=1))
        L = D - W
        D_norm = np.diag(1.0 / np.sqrt(np.diag(D)))
        L_norm = D_norm @ L @ D_norm

        # Compute eigenvectors
        eigenvalues, eigenvectors = eigsh(L_norm, k=self.n_eigenvectors,
                                        which='SM', sigma=1e-8)

        return eigenvalues, eigenvectors

    def detect_spectral_gaps(self, eigenvalues):
        """
        Detects spectral gaps to determine manifold structure.
        """
        gaps = np.diff(eigenvalues)
        significant_gaps = np.where(gaps > np.mean(gaps) + 2*np.std(gaps))[0]
        return significant_gaps

    def compute_heat_kernel_signature(self, X, t_range=None):
        """
        Computes heat kernel signatures for shape analysis.
        """
        if t_range is None:
            t_range = np.logspace(-2, 2, 50)

        eigenvalues, eigenvectors = self.compute_laplacian_eigenmaps(X)

        hks = np.zeros((len(X), len(t_range)))
        for i, t in enumerate(t_range):
            hks[:, i] = np.sum(eigenvectors**2 * np.exp(-eigenvalues * t), axis=1)

        return hks

class RiemannianMetricLearner:
    """
    Learns local Riemannian metrics for the manifold.
    """

    def __init__(self, n_neighbors=15, reg_param=1e-8):
        self.n_neighbors = n_neighbors
        self.reg_param = reg_param

    def fit_local_metric(self, X, point_idx):
        """
        Fits a local Riemannian metric at a point.
        """
        # Get local neighborhood
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors).fit(X)
        distances, indices = nbrs.kneighbors(X[point_idx:point_idx+1])
        neighborhood = X[indices[0]]

        # Center and compute local covariance
        centered = neighborhood - np.mean(neighborhood, axis=0)
        cov = centered.T @ centered / len(centered)

        # Regularize and invert
        metric = np.linalg.inv(cov + self.reg_param * np.eye(cov.shape[0]))

        return metric

    def parallel_transport(self, metric1, metric2, tangent_vector):
        """
        Parallel transports a tangent vector between metrics.
        """
        # Compute transformation matrix
        transform = np.linalg.cholesky(metric2 @ np.linalg.inv(metric1))

        # Transport the vector
        transported = transform @ tangent_vector

        return transported

class GeometricDictionaryLearning(nn.Module):
    """
    Dictionary learning that respects manifold geometry.
    """

    def __init__(self, input_dim, code_dim, n_atoms, sparsity_reg=0.1):
        super().__init__()
        self.dictionary = nn.Parameter(torch.randn(input_dim, n_atoms))
        self.code_dim = code_dim
        self.sparsity_reg = sparsity_reg

    def forward(self, x, local_metric=None):
        """
        Forward pass with geometric regularization.
        """
        # Project onto dictionary
        codes = F.linear(x, self.dictionary)

        # Soft thresholding for sparsity
        codes = F.softshrink(codes, self.sparsity_reg)

        # Reconstruction
        recon = F.linear(codes, self.dictionary.t())

        # Add geometric regularization if metric provided
        if local_metric is not None:
            metric_tensor = torch.tensor(local_metric, dtype=torch.float32)
            geom_error = torch.sum((x - recon) * (metric_tensor @ (x - recon).t()).t())
        else:
            geom_error = 0

        return recon, codes, geom_error

class StratifiedManifoldLearner:
    """
    Main class for learning stratified manifolds.
    """

    def __init__(self, max_dim=100, min_dim=1, n_neighbors=15):
        self.dim_estimator = LocalDimensionEstimator(n_neighbors)
        self.intersection_detector = ManifoldIntersectionDetector(n_neighbors)
        self.harmonic_analyzer = GeometricHarmonicAnalysis(n_neighbors=n_neighbors)
        self.metric_learner = RiemannianMetricLearner(n_neighbors)
        self.max_dim = max_dim
        self.min_dim = min_dim
        self.n_neighbors = n_neighbors

    def fit(self, X, init_labels=None):
        """
        Fits the stratified manifold model.
        """
        N = len(X)

        # Create neighborhoods for dimension estimation
        nbrs = NearestNeighbors(n_neighbors=min(self.n_neighbors * 2, N)).fit(X)

        # 1. Estimate local dimensions
        local_dims = np.zeros(N)
        for i in range(N):
            # Get local neighborhood for dimension estimation
            _, indices = nbrs.kneighbors(X[i:i+1])
            local_region = X[indices[0]]

            # Estimate dimension using local neighborhood as context
            dims = self.dim_estimator.estimate_dimension(
                X[i:i+1],
                local_region=local_region
            )
            local_dims[i] = dims['dimension']

        # 2. Initial stratification based on dimension
        if init_labels is None:
            unique_dims = np.unique(np.round(local_dims))
            labels = np.zeros(N, dtype=int)
            for i, dim in enumerate(unique_dims):
                mask = np.abs(local_dims - dim) < 0.5
                labels[mask] = i

        # 3. Detect and handle intersections
        intersections = []
        for i in range(N):
            is_intersection, angles = self.intersection_detector.detect_intersection(
                X, labels, i)
            if is_intersection:
                intersections.append((i, angles))

        # 4. Learn geometric structure
        eigenvalues, eigenvectors = self.harmonic_analyzer.compute_laplacian_eigenmaps(X)
        spectral_gaps = self.harmonic_analyzer.detect_spectral_gaps(eigenvalues)

        # 5. Learn local metrics
        metrics = {}
        for i in range(N):
            metrics[i] = self.metric_learner.fit_local_metric(X, i)

        self.local_dims_ = local_dims
        self.labels_ = labels
        self.intersections_ = intersections
        self.eigenvalues_ = eigenvalues
        self.eigenvectors_ = eigenvectors
        self.spectral_gaps_ = spectral_gaps
        self.metrics_ = metrics

        return self

    def transform(self, X):
        """
        Projects data onto learned stratified structure.
        """
        # Use eigenvectors for initial projection
        projection = X @ self.eigenvectors_

        return projection

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.linalg import solve_sylvester
from scipy.sparse.linalg import eigsh
from sklearn.neighbors import NearestNeighbors

class DifferentialGeometryTools:
    """
    Tools for computing differential geometric quantities on manifolds.
    """
    def __init__(self, n_neighbors=15):
        self.n_neighbors = n_neighbors

    def compute_christoffel_symbols(self, X, metric_tensors):
        """
        Computes Christoffel symbols for parallel transport.

        Args:
            X: (n_samples, dimension) array of points
            metric_tensors: Dictionary mapping indices to metric tensors
        """
        n_samples = len(X)
        dim = X.shape[1]
        christoffel = np.zeros((n_samples, dim, dim, dim))

        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(X)

        for i in range(n_samples):
            # Get local neighborhood
            distances, indices = nbrs.kneighbors(X[i:i+1])
            neighborhood = X[indices[0]]

            # Compute metric derivatives using finite differences
            metric_derivatives = self._compute_metric_derivatives(
                neighborhood,
                [metric_tensors[idx] for idx in indices[0]]
            )

            # Compute Christoffel symbols
            g_inv = np.linalg.inv(metric_tensors[i])
            for k in range(dim):
                for i_idx in range(dim):
                    for j in range(dim):
                        sum_term = 0
                        for l in range(dim):
                            sum_term += 0.5 * g_inv[k, l] * (
                                metric_derivatives[i_idx, l, j] +
                                metric_derivatives[j, l, i_idx] -
                                metric_derivatives[l, i_idx, j]
                            )
                        christoffel[i, k, i_idx, j] = sum_term

        return christoffel

    def _compute_metric_derivatives(self, neighborhood, metrics):
        """
        Computes derivatives of metric tensor using finite differences.
        """
        dim = neighborhood.shape[1]
        metric_derivatives = np.zeros((dim, dim, dim))

        # Center point
        center = np.mean(neighborhood, axis=0)
        center_metric = metrics[0]

        # Compute derivatives using finite differences
        for d in range(dim):
            # Points slightly offset in dimension d
            eps = 1e-6
            offset = np.zeros(dim)
            offset[d] = eps

            # Find nearest points in positive and negative directions
            pos_idx = np.argmin(np.linalg.norm(neighborhood - (center + offset), axis=1))
            neg_idx = np.argmin(np.linalg.norm(neighborhood - (center - offset), axis=1))

            # Compute derivative using central difference
            metric_derivatives[d] = (metrics[pos_idx] - metrics[neg_idx]) / (2 * eps)

        return metric_derivatives

class GeometricFlow:
    """
    Implements various geometric flows on manifolds.
    """
    def __init__(self, n_neighbors=15, time_steps=100, step_size=0.01):
        self.n_neighbors = n_neighbors
        self.time_steps = time_steps
        self.step_size = step_size
        self.geom_tools = DifferentialGeometryTools(n_neighbors)

    def mean_curvature_flow(self, X, metric_tensors):
        """
        Implements mean curvature flow on the manifold.
        """
        n_samples = len(X)
        dim = X.shape[1]

        # Initialize flow
        flow = np.zeros((self.time_steps, n_samples, dim))
        flow[0] = X

        for t in range(1, self.time_steps):
            # Compute mean curvature vector at each point
            H = self._compute_mean_curvature(flow[t-1], metric_tensors)

            # Update points
            flow[t] = flow[t-1] - self.step_size * H

            # Project back onto manifold if needed
            flow[t] = self._project_to_manifold(flow[t], X, metric_tensors)

        return flow

    def ricci_flow(self, X, metric_tensors):
        """
        Implements Ricci flow on the manifold.
        """
        n_samples = len(X)
        dim = X.shape[1]

        # Initialize flow
        metric_flow = []
        for t in range(self.time_steps):
            # Compute Ricci tensor
            ricci = self._compute_ricci_tensor(X, metric_tensors)

            # Update metric
            new_metrics = {}
            for i in range(n_samples):
                new_metrics[i] = metric_tensors[i] - self.step_size * ricci[i]
                # Ensure metric remains positive definite
                w, v = np.linalg.eigh(new_metrics[i])
                w = np.maximum(w, 1e-6)
                new_metrics[i] = v @ np.diag(w) @ v.T

            metric_flow.append(new_metrics)
            metric_tensors = new_metrics

        return metric_flow

    def parallel_transport(self, X, vector_field, metric_tensors):
        """
        Parallel transports a vector field along the manifold.
        """
        n_samples = len(X)
        dim = X.shape[1]

        # Compute Christoffel symbols
        christoffel = self.geom_tools.compute_christoffel_symbols(X, metric_tensors)

        # Initialize transported field
        transported = np.zeros_like(vector_field)

        # Transport along geodesics
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(X)

        for i in range(n_samples):
            # Get local path
            distances, indices = nbrs.kneighbors(X[i:i+1])
            path = X[indices[0]]

            # Transport along path
            v = vector_field[i]
            for j in range(1, len(path)):
                tangent = path[j] - path[j-1]
                # Parallel transport equation
                for k in range(dim):
                    for l in range(dim):
                        v[k] -= np.sum(christoffel[j-1, k, l, :] * tangent * v[l])

            transported[i] = v

        return transported

    def _compute_mean_curvature(self, X, metric_tensors):
        """
        Computes mean curvature vector at each point.
        """
        n_samples = len(X)
        dim = X.shape[1]
        H = np.zeros_like(X)

        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(X)

        for i in range(n_samples):
            # Get local neighborhood
            distances, indices = nbrs.kneighbors(X[i:i+1])
            neighborhood = X[indices[0]]

            # Compute local parameterization
            centered = neighborhood - X[i]
            U, S, Vt = np.linalg.svd(centered)

            # Project neighborhood onto tangent space
            tangent_coords = centered @ Vt[:dim-1].T

            # Compute second fundamental form
            g_inv = np.linalg.inv(metric_tensors[i])
            B = self._compute_second_fundamental_form(
                tangent_coords,
                neighborhood - X[i],
                g_inv
            )

            # Compute mean curvature vector
            H[i] = np.trace(B @ g_inv)

        return H

    def _compute_second_fundamental_form(self, tangent_coords, normal_coords, metric):
        """
        Computes second fundamental form for mean curvature calculation.
        """
        # Fit quadratic form to normal coordinates
        X = np.c_[tangent_coords, 0.5 * np.prod(tangent_coords, axis=1)]
        B = np.linalg.lstsq(X, normal_coords, rcond=None)[0]
        return B

    def _compute_ricci_tensor(self, X, metric_tensors):
        """
        Computes Ricci tensor for Ricci flow.
        """
        n_samples = len(X)
        dim = X.shape[1]
        ricci = np.zeros((n_samples, dim, dim))

        # Compute Christoffel symbols
        christoffel = self.geom_tools.compute_christoffel_symbols(X, metric_tensors)

        for i in range(n_samples):
            # Compute Riemann curvature tensor
            R = np.zeros((dim, dim, dim, dim))
            for k in range(dim):
                for l in range(dim):
                    for m in range(dim):
                        for n in range(dim):
                            term1 = np.sum(christoffel[i, k, l, :] * christoffel[i, :, m, n])
                            term2 = np.sum(christoffel[i, k, m, :] * christoffel[i, :, l, n])
                            R[k, l, m, n] = term1 - term2

            # Contract to get Ricci tensor
            for j in range(dim):
                for k in range(dim):
                    ricci[i, j, k] = np.trace(R[:, j, :, k])

        return ricci

    def _project_to_manifold(self, points, original_points, metric_tensors):
        """
        Projects points back onto the manifold using local metric structure.
        """
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(original_points)

        projected = np.zeros_like(points)
        for i in range(len(points)):
            # Get local neighborhood
            distances, indices = nbrs.kneighbors(points[i:i+1])
            neighborhood = original_points[indices[0]]

            # Compute local PCA
            centered = neighborhood - np.mean(neighborhood, axis=0)
            U, S, Vt = np.linalg.svd(centered)

            # Project onto tangent space
            local_dim = np.sum(S > 1e-6)
            projection = Vt[:local_dim].T @ Vt[:local_dim]

            # Project point
            projected[i] = np.mean(neighborhood, axis=0) + projection @ (points[i] - np.mean(neighborhood, axis=0))

        return projected

class ManifoldPatchingSystem:
    """
    System for handling transitions between different manifold patches.
    """
    def __init__(self, n_neighbors=15):
        self.n_neighbors = n_neighbors

    def compute_transition_maps(self, X, labels, metric_tensors):
        """
        Computes transition maps between different manifold patches.
        """
        n_samples = len(X)
        transitions = {}

        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(X)

        for i in range(n_samples):
            # Get local neighborhood
            distances, indices = nbrs.kneighbors(X[i:i+1])
            neighborhood_labels = labels[indices[0]]

            # Check for different labels in neighborhood
            unique_labels = np.unique(neighborhood_labels)
            if len(unique_labels) > 1:
                # Compute transition map for each pair of patches
                for l1 in unique_labels:
                    for l2 in unique_labels:
                        if l1 < l2:
                            transition = self._compute_transition(
                                X[indices[0]],
                                neighborhood_labels,
                                l1, l2,
                                metric_tensors
                            )
                            transitions[(i, l1, l2)] = transition

        return transitions

    def _compute_transition(self, points, labels, label1, label2, metric_tensors):
        """
        Computes transition map between two patches.
        """
        # Points in each patch
        mask1 = labels == label1
        mask2 = labels == label2
        points1 = points[mask1]
        points2 = points[mask2]

        # Compute mean and covariance for each patch
        mean1 = np.mean(points1, axis=0)
        mean2 = np.mean(points2, axis=0)
        cov1 = np.cov(points1.T)
        cov2 = np.cov(points2.T)

        # Solve for transition matrix
        A = solve_sylvester(cov1, -cov2, (mean1 - mean2).reshape(-1, 1))

        return {
            'matrix': A,
            'mean1': mean1,
            'mean2': mean2,
            'cov1': cov1,
            'cov2': cov2
        }

    def apply_transition(self, point, transition):
        """
        Applies transition map to a point.
        """
        return transition['matrix'].T @ (point - transition['mean1']) + transition['mean2']

    def compute_partition_of_unity(self, X, labels):
        """
        Computes smooth partition of unity for manifold patches.
        """
        n_samples = len(X)
        unique_labels = np.unique(labels)
        partition = np.zeros((n_samples, len(unique_labels)))

        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors)
        nbrs.fit(X)

        for i in range(n_samples):
            # Get local neighborhood
            distances, indices = nbrs.kneighbors(X[i:i+1])
            neighborhood_labels = labels[indices[0]]

            # Compute weights using Gaussian kernel
            sigma = np.mean(distances[0])
            weights = np.exp(-distances[0]**2 / (2 * sigma**2))

            # Assign weights to each label
            for j, label in enumerate(unique_labels):
                mask = neighborhood_labels == label
                partition[i, j] = np.sum(weights[mask])

        # Normalize
        partition /= np.sum(partition, axis=1, keepdims=True)

        return partition

import numpy as np
from sklearn.neighbors import NearestNeighbors
import warnings

class SmallDatasetHandler:
    """Base class for handling small dataset operations"""

    def __init__(self, min_neighbors=3):
        self.min_neighbors = min_neighbors

    def get_safe_n_neighbors(self, n_samples, requested_neighbors):
        """Compute safe number of neighbors based on sample size"""
        return min(max(self.min_neighbors, requested_neighbors), n_samples - 1)

    def compute_local_neighborhood(self, X, point_idx, n_neighbors=None):
        """Safely compute local neighborhood even for small datasets"""
        if n_neighbors is None:
            n_neighbors = self.min_neighbors

        n_samples = len(X)
        effective_n = self.get_safe_n_neighbors(n_samples, n_neighbors)

        nbrs = NearestNeighbors(n_neighbors=effective_n + 1).fit(X)
        distances, indices = nbrs.kneighbors(X[point_idx:point_idx+1])

        return distances[0], indices[0], effective_n

class LocalDimensionEstimator(SmallDatasetHandler):
    """Enhanced dimension estimator for small datasets"""

    def __init__(self, n_neighbors=15, min_neighbors=3):
        super().__init__(min_neighbors)
        self.n_neighbors = n_neighbors

    def estimate_dimension(self, X, point_idx):
        """Estimate local dimension robustly"""
        distances, indices, effective_n = self.compute_local_neighborhood(
            X, point_idx, self.n_neighbors)

        if effective_n < self.min_neighbors:
            warnings.warn(f"Very small neighborhood size ({effective_n}). Dimension estimates may be unreliable.")
            return {
                'dimension': 1.0,
                'mle': 1.0,
                'mle_std': 0.0,
                'correlation': 1.0,
                'tda': 1.0
            }

        try:
            # MLE estimation with error handling
            log_dists = np.log(distances[1:] / distances[-1])
            with warnings.catch_warnings():
                warnings.filterwarnings('ignore')
                inv_mle = np.nanmean(log_dists)
                mle_dim = -1 / inv_mle if inv_mle != 0 else 1.0
                mle_std = np.nanstd(log_dists) if len(log_dists) > 1 else 0.0

            # Ensure reasonable values
            mle_dim = np.clip(mle_dim, 1.0, X.shape[1])

            return {
                'dimension': mle_dim,
                'mle': mle_dim,
                'mle_std': mle_std,
                'correlation': mle_dim,  # Simplified for small datasets
                'tda': mle_dim  # Simplified for small datasets
            }

        except (ValueError, ZeroDivisionError) as e:
            warnings.warn(f"Error in dimension estimation: {str(e)}. Returning default values.")
            return {
                'dimension': 1.0,
                'mle': 1.0,
                'mle_std': 0.0,
                'correlation': 1.0,
                'tda': 1.0
            }

class ManifoldIntersectionDetector(SmallDatasetHandler):
    """Enhanced intersection detector for small datasets"""

    def __init__(self, n_neighbors=15, min_neighbors=3):
        super().__init__(min_neighbors)
        self.n_neighbors = n_neighbors

    def detect_intersection(self, X, labels, point_idx):
        """Detect intersections with robust handling of small neighborhoods"""
        distances, indices, effective_n = self.compute_local_neighborhood(
            X, point_idx, self.n_neighbors)

        # Get labels of neighborhood
        neighborhood_labels = labels[indices]
        unique_labels = np.unique(neighborhood_labels)

        # For very small datasets, be more conservative about intersection detection
        if effective_n < self.min_neighbors:
            return False, None

        if len(unique_labels) > 1:
            # Compute simplified intersection angles for small datasets
            angles = self._compute_simple_angles(X[indices], neighborhood_labels, unique_labels)
            return True, angles

        return False, None

    def _compute_simple_angles(self, neighborhood, labels, unique_labels):
        """Compute simplified angles for small neighborhoods"""
        angles = []
        for i, label1 in enumerate(unique_labels[:-1]):
            for label2 in unique_labels[i+1:]:
                mask1 = labels == label1
                mask2 = labels == label2
                if np.sum(mask1) > 0 and np.sum(mask2) > 0:
                    # Compute direction vectors
                    mean1 = np.mean(neighborhood[mask1], axis=0)
                    mean2 = np.mean(neighborhood[mask2], axis=0)
                    v1 = mean1 - np.mean(neighborhood, axis=0)
                    v2 = mean2 - np.mean(neighborhood, axis=0)

                    # Compute angle
                    if np.any(v1) and np.any(v2):
                        cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        angles.append(np.arccos(np.clip(cos_theta, -1.0, 1.0)))

        return angles if angles else [np.pi/2]  # Default angle if computation fails

class StratifiedManifoldLearner(SmallDatasetHandler):
    """Enhanced manifold learner for small datasets"""

    def __init__(self, max_dim=100, min_dim=1, n_neighbors=15, min_neighbors=3):
        super().__init__(min_neighbors)
        self.max_dim = max_dim
        self.min_dim = min_dim
        self.n_neighbors = n_neighbors
        self.dim_estimator = LocalDimensionEstimator(n_neighbors, min_neighbors)
        self.intersection_detector = ManifoldIntersectionDetector(n_neighbors, min_neighbors)

    def fit(self, X, init_labels=None):
        """Fit the model with robust handling of small datasets"""
        N = len(X)
        effective_n = self.get_safe_n_neighbors(N, self.n_neighbors)

        print(f"Using {effective_n} neighbors for a dataset of size {N}")

        # 1. Estimate local dimensions
        local_dims = np.zeros(N)
        for i in range(N):
            dims = self.dim_estimator.estimate_dimension(X, i)
            local_dims[i] = dims['dimension']

        # 2. Initial stratification
        if init_labels is None:
            unique_dims = np.unique(np.round(local_dims))
            labels = np.zeros(N, dtype=int)
            for i, dim in enumerate(unique_dims):
                mask = np.abs(local_dims - dim) < 0.5
                labels[mask] = i
        else:
            labels = init_labels

        # 3. Detect intersections
        intersections = []
        for i in range(N):
            is_intersection, angles = self.intersection_detector.detect_intersection(
                X, labels, i)
            if is_intersection and angles is not None:
                intersections.append((i, angles))

        self.local_dims_ = local_dims
        self.labels_ = labels
        self.intersections_ = intersections

        return self

    def transform(self, X):
        """Transform data with safe handling of small datasets"""
        # For small datasets, use simplified transformation
        if len(X) < self.min_neighbors * 2:
            warnings.warn("Small dataset: using simplified transformation")
            return X  # Return original data

        # Otherwise proceed with normal transformation
        return X  # Placeholder for actual transformation

import torch
from transformers import AutoModel, AutoTokenizer
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import List, Dict, Tuple
import matplotlib.pyplot as plt
from tqdm import tqdm

class LLMManifoldAnalyzer:
    """
    Integrates LLM embeddings with stratified manifold analysis.
    """
    def __init__(
        self,
        model_name: str = "bert-base-uncased",
        n_neighbors: int = 15,
        batch_size: int = 32
    ):
        self.model_name = model_name
        self.n_neighbors = n_neighbors
        self.batch_size = batch_size

        # Initialize components
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()

        self.manifold_learner = StratifiedManifoldLearner(
            max_dim=self.model.config.hidden_size,
            min_dim=1,
            n_neighbors=n_neighbors
        )

        self.flow_computer = GeometricFlow(
            n_neighbors=n_neighbors
        )

        self.patch_system = ManifoldPatchingSystem(
            n_neighbors=n_neighbors
        )

        self.scaler = StandardScaler()

    def compute_embeddings(self, texts: List[str]) -> np.ndarray:
        """
        Computes LLM embeddings for a list of texts.
        """
        embeddings = []

        with torch.no_grad():
            for i in range(0, len(texts), self.batch_size):
                batch_texts = texts[i:i + self.batch_size]
                inputs = self.tokenizer(
                    batch_texts,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=512
                )

                outputs = self.model(**inputs)
                # Use CLS token embeddings
                batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()
                embeddings.append(batch_embeddings)

        embeddings = np.vstack(embeddings)
        return embeddings

    def analyze_manifold_structure(
        self,
        texts: List[str],
        domain_labels: List[str] = None
    ) -> Dict:
        """
        Performs complete manifold analysis on text embeddings.
        """
        print("Computing embeddings...")
        embeddings = self.compute_embeddings(texts)

        # Normalize embeddings
        embeddings_normalized = self.scaler.fit_transform(embeddings)

        print("Fitting manifold learner...")
        self.manifold_learner.fit(embeddings_normalized)

        # Transform embeddings
        embeddings_transformed = self.manifold_learner.transform(embeddings_normalized)

        # Compute metric tensors
        print("Computing metric tensors...")
        metric_tensors = self._compute_metric_tensors(embeddings_normalized)

        # Compute geometric flows
        print("Computing geometric flows...")
        flows = self._compute_flows(embeddings_normalized, metric_tensors)

        # Analyze transitions between patches
        print("Analyzing patch transitions...")
        transitions = self.patch_system.compute_transition_maps(
            embeddings_normalized,
            self.manifold_learner.labels_,
            metric_tensors
        )

        # Compute partition of unity
        partition = self.patch_system.compute_partition_of_unity(
            embeddings_normalized,
            self.manifold_learner.labels_
        )

        return {
            'embeddings': embeddings,
            'embeddings_normalized': embeddings_normalized,
            'embeddings_transformed': embeddings_transformed,
            'local_dimensions': self.manifold_learner.local_dims_,
            'labels': self.manifold_learner.labels_,
            'intersections': self.manifold_learner.intersections_,
            'flows': flows,
            'transitions': transitions,
            'partition': partition
        }

    def _compute_metric_tensors(self, X: np.ndarray) -> Dict[int, np.ndarray]:
        """
        Computes metric tensors for each point.
        """
        metric_tensors = {}
        for i in range(len(X)):
            metric_tensors[i] = self.manifold_learner.metric_learner.fit_local_metric(X, i)
        return metric_tensors

    def _compute_flows(
        self,
        X: np.ndarray,
        metric_tensors: Dict[int, np.ndarray]
    ) -> Dict[str, np.ndarray]:
        """
        Computes different types of geometric flows.
        """
        return {
            'mean_curvature': self.flow_computer.mean_curvature_flow(X, metric_tensors),
            'ricci': self.flow_computer.ricci_flow(X, metric_tensors)
        }

    def visualize_analysis(
        self,
        analysis_results: Dict,
        texts: List[str],
        domain_labels: List[str] = None
    ):
        """
        Creates comprehensive visualizations of the manifold analysis.
        """
        # 1. Dimension Distribution
        plt.figure(figsize=(10, 6))
        plt.hist(analysis_results['local_dimensions'], bins=30)
        plt.title('Distribution of Local Dimensions')
        plt.xlabel('Dimension')
        plt.ylabel('Count')
        plt.show()

        # 2. Stratum Labels Distribution
        if domain_labels is not None:
            plt.figure(figsize=(12, 6))
            for label in np.unique(analysis_results['labels']):
                mask = analysis_results['labels'] == label
                plt.scatter(
                    analysis_results['embeddings_transformed'][mask, 0],
                    analysis_results['embeddings_transformed'][mask, 1],
                    label=f'Stratum {label}'
                )
            plt.title('Transformed Embeddings by Stratum')
            plt.xlabel('Component 1')
            plt.ylabel('Component 2')
            plt.legend()
            plt.show()

        # 3. Flow Visualization
        self._visualize_flows(analysis_results['flows'])

        # 4. Transition Region Analysis
        self._visualize_transitions(
            analysis_results['embeddings_normalized'],
            analysis_results['transitions'],
            analysis_results['labels']
        )

        # 5. Partition of Unity
        self._visualize_partition(analysis_results['partition'])

    def _visualize_flows(self, flows: Dict[str, np.ndarray]):
        """
        Visualizes geometric flows on the manifold.
        """
        fig = plt.figure(figsize=(15, 5))

        # Mean Curvature Flow
        ax1 = fig.add_subplot(121, projection='3d')
        for t in range(0, flows['mean_curvature'].shape[0], 10):
            ax1.scatter(
                flows['mean_curvature'][t, :, 0],
                flows['mean_curvature'][t, :, 1],
                flows['mean_curvature'][t, :, 2],
                alpha=0.5
            )
        ax1.set_title('Mean Curvature Flow')

        # Ricci Flow
        ax2 = fig.add_subplot(122)
        ricci_norms = np.array([
            [np.linalg.norm(metric) for metric in time_slice.values()]
            for time_slice in flows['ricci']
        ])
        ax2.plot(ricci_norms.mean(axis=1))
        ax2.set_title('Ricci Flow: Metric Evolution')
        ax2.set_xlabel('Time')
        ax2.set_ylabel('Average Metric Norm')

        plt.tight_layout()
        plt.show()

    def _visualize_transitions(
        self,
        X: np.ndarray,
        transitions: Dict,
        labels: np.ndarray
    ):
        """
        Visualizes transition regions between manifold patches.
        """
        plt.figure(figsize=(10, 10))

        # Plot all points
        plt.scatter(X[:, 0], X[:, 1], c=labels, alpha=0.5)

        # Highlight transition regions
        for (idx, _, _), transition in transitions.items():
            plt.scatter(
                X[idx, 0],
                X[idx, 1],
                c='red',
                marker='*',
                s=100
            )

        plt.title('Manifold Patches and Transition Regions')
        plt.show()

    def _visualize_partition(self, partition: np.ndarray):
        """
        Visualizes the partition of unity.
        """
        plt.figure(figsize=(10, 6))
        for i in range(partition.shape[1]):
            plt.plot(partition[:, i], label=f'Patch {i}')
        plt.title('Partition of Unity Weights')
        plt.xlabel('Point Index')
        plt.ylabel('Weight')
        plt.legend()
        plt.show()

def main():
    # Example usage
    analyzer = LLMManifoldAnalyzer()

    # Example texts from different domains
    texts = [
        # Technical
        "The quantum computer utilizes superposition principles.",
        "Neural networks learn through backpropagation.",
        # Literary
        "The autumn leaves danced in the morning breeze.",
        "Moonlight cast shadows on ancient stone walls.",
        # Conversational
        "Hey, how are you doing today?",
        "Can you help me find my keys?"
    ]

    domain_labels = [
        "technical", "technical",
        "literary", "literary",
        "conversational", "conversational"
    ]

    # Perform analysis
    results = analyzer.analyze_manifold_structure(texts, domain_labels)

    # Visualize results
    analyzer.visualize_analysis(results, texts, domain_labels)

    # Print summary statistics
    print("\nAnalysis Summary:")
    print(f"Number of strata: {len(np.unique(results['labels']))}")
    print(f"Average local dimension: {np.mean(results['local_dimensions']):.2f}")
    print(f"Number of intersection regions: {len(results['intersections'])}")

    # Example of extracting semantic features
    print("\nSemantic Feature Analysis:")
    for i, text in enumerate(texts):
        print(f"\nText: {text}")
        print(f"Local dimension: {results['local_dimensions'][i]:.2f}")
        print(f"Stratum: {results['labels'][i]}")
        if any(idx == i for idx, _ in results['intersections']):
            print("Located in intersection region")

if __name__ == "__main__":
    main()

